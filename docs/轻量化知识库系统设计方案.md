# è½»é‡åŒ–çŸ¥è¯†åº“ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ

## é¡¹ç›®æ¦‚è¿°

æœ¬æ–¹æ¡ˆè®¾è®¡äº†ä¸€ä¸ªè½»é‡åŒ–çš„çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿï¼Œå°†é«˜è€—èƒ½çš„æ–‡æ¡£è§£æå’ŒçŸ¥è¯†å›¾è°±ç”Ÿæˆä»»åŠ¡å¤–åŒ…ç»™ä¸“ä¸šçš„å¤–éƒ¨æœåŠ¡ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿä¸“æ³¨äºæ ¸å¿ƒçš„æŸ¥è¯¢ã€ç®¡ç†ã€ç¼“å­˜å’Œç”¨æˆ·äº¤äº’åŠŸèƒ½ã€‚

### è®¾è®¡ç†å¿µ
- **ä¸“ä¸šåˆ†å·¥**ï¼šå°†å¤æ‚ä»»åŠ¡äº¤ç»™ä¸“ä¸šæœåŠ¡å¤„ç†
- **è½»é‡é«˜æ•ˆ**ï¼šç³»ç»Ÿä¿æŒè½»é‡çº§ï¼Œä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½
- **æœåŠ¡ç¼–æ’**ï¼šé€šè¿‡APIç¼–æ’å„ç§å¤–éƒ¨æœåŠ¡
- **æ™ºèƒ½ç¼“å­˜**ï¼šå‡å°‘å¤–éƒ¨æœåŠ¡è°ƒç”¨ï¼Œæå‡å“åº”é€Ÿåº¦
- **ç”¨æˆ·ä½“éªŒ**ï¼šæä¾›ç»Ÿä¸€ã€æµç•…çš„ç”¨æˆ·äº¤äº’ç•Œé¢

## æ•´ä½“æ¶æ„è®¾è®¡

### ç³»ç»Ÿåˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           User Interface Layer ç”¨æˆ·ç•Œé¢å±‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Web Dashboard   â”‚  â”‚ API Gateway     â”‚  â”‚ Chat Interface  â”‚  â”‚ Admin Panel     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Core Business Layer æ ¸å¿ƒä¸šåŠ¡å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Query Engine    â”‚  â”‚ Knowledge       â”‚  â”‚ Service         â”‚  â”‚ Session         â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚ Manager         â”‚  â”‚ Orchestrator    â”‚  â”‚ Manager         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Service Integration Layer æœåŠ¡é›†æˆå±‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ External        â”‚  â”‚ Cache           â”‚  â”‚ Message         â”‚  â”‚ Health          â”‚ â”‚
â”‚  â”‚ Service Client  â”‚  â”‚ Manager         â”‚  â”‚ Queue           â”‚  â”‚ Monitor         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Storage Layer æ•°æ®å­˜å‚¨å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Metadata Store  â”‚  â”‚ Cache Store     â”‚  â”‚ Session Store   â”‚  â”‚ Config Store    â”‚ â”‚
â”‚  â”‚ (PostgreSQL)    â”‚  â”‚ (Redis)         â”‚  â”‚ (Redis)         â”‚  â”‚ (Local/Consul)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        External Services å¤–éƒ¨æœåŠ¡å±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Unstructured    â”‚  â”‚ Microsoft       â”‚  â”‚ Vector DB       â”‚  â”‚ LLM Services    â”‚ â”‚
â”‚  â”‚ (æ–‡æ¡£è§£æ)       â”‚  â”‚ GraphRAG        â”‚  â”‚ (Chroma/Pinecone)â”‚  â”‚ (OpenAI/Claude) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å¤–éƒ¨æœåŠ¡é›†æˆç­–ç•¥

### 1. æ–‡æ¡£è§£ææœåŠ¡ - Unstructured

```python
# src/core/knowledge/external/unstructured_client.py
from typing import Dict, List, Optional, Any
import aiohttp
import asyncio
from datetime import datetime

class UnstructuredClient:
    """Unstructuredæ–‡æ¡£è§£ææœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict[str, Any]):
        self.api_url = config.get("api_url", "http://unstructured:8000")
        self.api_key = config.get("api_key")
        self.timeout = config.get("timeout", 300)
        self.max_retries = config.get("max_retries", 3)
        
    async def parse_document(
        self,
        file_content: bytes,
        filename: str,
        parsing_strategy: str = "hi_res"
    ) -> Dict[str, Any]:
        """è§£ææ–‡æ¡£"""
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
            data = aiohttp.FormData()
            data.add_field('files', file_content, filename=filename)
            data.add_field('strategy', parsing_strategy)
            data.add_field('extract_images_in_pdf', 'true')
            data.add_field('infer_table_structure', 'true')
            data.add_field('ocr_languages', 'eng,chi_sim')
            
            headers = {}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
            
            for attempt in range(self.max_retries):
                try:
                    async with session.post(
                        f"{self.api_url}/general/v0/general",
                        data=data,
                        headers=headers
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            return self._process_unstructured_response(result)
                        else:
                            error_text = await response.text()
                            raise Exception(f"Unstructured API error: {response.status}, {error_text}")
                            
                except Exception as e:
                    if attempt == self.max_retries - 1:
                        raise
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
    def _process_unstructured_response(self, response: List[Dict]) -> Dict[str, Any]:
        """å¤„ç†Unstructuredå“åº”"""
        processed_doc = {
            "title": "",
            "sections": [],
            "tables": [],
            "images": [],
            "metadata": {
                "total_elements": len(response),
                "parsed_at": datetime.utcnow().isoformat()
            }
        }
        
        current_section = None
        
        for element in response:
            element_type = element.get("type", "")
            text = element.get("text", "").strip()
            
            if element_type == "Title" and not processed_doc["title"]:
                processed_doc["title"] = text
                
            elif element_type in ["Title", "Header"]:
                current_section = {
                    "title": text,
                    "content": [],
                    "level": self._get_header_level(element)
                }
                processed_doc["sections"].append(current_section)
                
            elif element_type == "Table":
                processed_doc["tables"].append({
                    "content": text,
                    "html": element.get("metadata", {}).get("text_as_html", ""),
                    "page_number": element.get("metadata", {}).get("page_number")
                })
                
            elif element_type in ["NarrativeText", "ListItem", "Text"]:
                if current_section:
                    current_section["content"].append(text)
                else:
                    if not processed_doc["sections"]:
                        processed_doc["sections"].append({
                            "title": "Content",
                            "content": [],
                            "level": 1
                        })
                    processed_doc["sections"][0]["content"].append(text)
        
        return processed_doc
    
    def _get_header_level(self, element: Dict) -> int:
        """æ¨æ–­æ ‡é¢˜å±‚çº§"""
        metadata = element.get("metadata", {})
        # å¯ä»¥æ ¹æ®å­—ä½“å¤§å°ã€æ ·å¼ç­‰æ¨æ–­å±‚çº§
        return metadata.get("header_level", 1)
```

### 2. çŸ¥è¯†å›¾è°±æœåŠ¡ - Microsoft GraphRAG

```python
# src/core/knowledge/external/graphrag_client.py
from typing import Dict, List, Optional, Any
import aiohttp
import asyncio

class GraphRAGClient:
    """Microsoft GraphRAGæœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict[str, Any]):
        self.api_url = config.get("api_url", "http://graphrag:8001")
        self.api_key = config.get("api_key")
        self.timeout = config.get("timeout", 600)  # GraphRAGå¤„ç†æ—¶é—´è¾ƒé•¿
        
    async def build_knowledge_graph(
        self,
        documents: List[Dict[str, Any]],
        config: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """æ„å»ºçŸ¥è¯†å›¾è°±"""
        
        payload = {
            "documents": documents,
            "config": config or {
                "chunk_size": 300,
                "chunk_overlap": 100,
                "community_algorithm": "leiden",
                "entity_extraction_model": "gpt-4",
                "relation_extraction_model": "gpt-4",
                "community_summarization_model": "gpt-4"
            }
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
                
            async with session.post(
                f"{self.api_url}/api/v1/build_graph",
                json=payload,
                headers=headers
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    error_text = await response.text()
                    raise Exception(f"GraphRAG API error: {response.status}, {error_text}")
    
    async def query_graph(
        self,
        query: str,
        query_type: str = "global",
        config: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """æŸ¥è¯¢çŸ¥è¯†å›¾è°±"""
        
        payload = {
            "query": query,
            "query_type": query_type,  # global/local
            "config": config or {
                "max_tokens": 4000,
                "community_level": 2,
                "max_depth": 2
            }
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
                
            async with session.post(
                f"{self.api_url}/api/v1/query",
                json=payload,
                headers=headers
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    error_text = await response.text()
                    raise Exception(f"GraphRAG query error: {response.status}, {error_text}")
    
    async def get_graph_status(self, graph_id: str) -> Dict[str, Any]:
        """è·å–å›¾è°±æ„å»ºçŠ¶æ€"""
        
        async with aiohttp.ClientSession() as session:
            headers = {}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
                
            async with session.get(
                f"{self.api_url}/api/v1/graphs/{graph_id}/status",
                headers=headers
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    return {"status": "error", "message": await response.text()}
```

### 3. å‘é‡æ•°æ®åº“æœåŠ¡ - å¼€æºæ–¹æ¡ˆ

```python
# src/core/knowledge/external/vector_db_client.py
from typing import Dict, List, Optional, Any
import chromadb
from chromadb.config import Settings

class VectorDBClient:
    """å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯ï¼ˆæ”¯æŒChromaã€Pineconeç­‰ï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        self.db_type = config.get("type", "chroma")
        self.config = config
        
        if self.db_type == "chroma":
            self.client = chromadb.HttpClient(
                host=config.get("host", "localhost"),
                port=config.get("port", 8000),
                settings=Settings(allow_reset=True)
            )
        elif self.db_type == "pinecone":
            import pinecone
            pinecone.init(
                api_key=config.get("api_key"),
                environment=config.get("environment")
            )
            self.client = pinecone
        
    async def create_collection(self, collection_name: str, metadata: Optional[Dict] = None):
        """åˆ›å»ºé›†åˆ"""
        if self.db_type == "chroma":
            return self.client.create_collection(
                name=collection_name,
                metadata=metadata or {}
            )
    
    async def add_documents(
        self,
        collection_name: str,
        documents: List[str],
        embeddings: List[List[float]],
        metadatas: List[Dict],
        ids: List[str]
    ):
        """æ·»åŠ æ–‡æ¡£"""
        if self.db_type == "chroma":
            collection = self.client.get_collection(collection_name)
            collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
    
    async def search_similar(
        self,
        collection_name: str,
        query_embedding: List[float],
        n_results: int = 10,
        where: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """ç›¸ä¼¼æ€§æœç´¢"""
        if self.db_type == "chroma":
            collection = self.client.get_collection(collection_name)
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where
            )
            return results
```

## æ ¸å¿ƒä¸šåŠ¡å±‚è®¾è®¡

### 1. çŸ¥è¯†ç®¡ç†å™¨

```python
# src/core/knowledge/knowledge_manager.py
from typing import Dict, List, Optional, Any
import asyncio
import logging
from datetime import datetime

class KnowledgeManager:
    """è½»é‡åŒ–çŸ¥è¯†ç®¡ç†å™¨ - ä¸“æ³¨äºæœåŠ¡ç¼–æ’å’Œç¼“å­˜"""
    
    def __init__(
        self,
        unstructured_client,
        graphrag_client,
        vector_db_client,
        cache_manager,
        metadata_store
    ):
        self.unstructured = unstructured_client
        self.graphrag = graphrag_client
        self.vector_db = vector_db_client
        self.cache = cache_manager
        self.metadata = metadata_store
        
        self.logger = logging.getLogger(__name__)
    
    async def process_document(
        self,
        file_content: bytes,
        filename: str,
        user_id: str
    ) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£çš„å®Œæ•´æµç¨‹"""
        
        doc_id = self._generate_doc_id()
        
        try:
            # 1. æ£€æŸ¥ç¼“å­˜
            cached_result = await self.cache.get_document_result(filename, file_content)
            if cached_result:
                self.logger.info(f"Document {filename} found in cache")
                return cached_result
            
            # 2. è°ƒç”¨Unstructuredè§£ææ–‡æ¡£
            self.logger.info(f"Parsing document {filename} with Unstructured")
            parsed_doc = await self.unstructured.parse_document(
                file_content=file_content,
                filename=filename
            )
            
            # 3. ä¿å­˜è§£æç»“æœåˆ°å…ƒæ•°æ®å­˜å‚¨
            await self.metadata.save_document_metadata(doc_id, {
                "filename": filename,
                "user_id": user_id,
                "parsed_at": datetime.utcnow().isoformat(),
                "status": "parsed",
                "sections_count": len(parsed_doc.get("sections", [])),
                "tables_count": len(parsed_doc.get("tables", [])),
                "images_count": len(parsed_doc.get("images", []))
            })
            
            # 4. å¼‚æ­¥å¯åŠ¨GraphRAGå¤„ç†
            asyncio.create_task(self._process_with_graphrag(doc_id, parsed_doc))
            
            # 5. ç¼“å­˜ç»“æœ
            result = {
                "doc_id": doc_id,
                "status": "processing",
                "parsed_content": parsed_doc,
                "message": "Document parsed successfully, knowledge graph generation in progress"
            }
            
            await self.cache.cache_document_result(filename, file_content, result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"Error processing document {filename}: {str(e)}")
            await self.metadata.update_document_status(doc_id, "error", str(e))
            raise
    
    async def _process_with_graphrag(self, doc_id: str, parsed_doc: Dict[str, Any]):
        """å¼‚æ­¥å¤„ç†GraphRAG"""
        try:
            # å‡†å¤‡GraphRAGè¾“å…¥
            documents = [{
                "doc_id": doc_id,
                "content": self._extract_text_content(parsed_doc),
                "metadata": parsed_doc.get("metadata", {})
            }]
            
            # è°ƒç”¨GraphRAGæ„å»ºçŸ¥è¯†å›¾è°±
            graph_result = await self.graphrag.build_knowledge_graph(documents)
            
            # æ›´æ–°çŠ¶æ€
            await self.metadata.update_document_status(doc_id, "completed")
            await self.metadata.save_graph_metadata(doc_id, graph_result)
            
            self.logger.info(f"GraphRAG processing completed for document {doc_id}")
            
        except Exception as e:
            self.logger.error(f"GraphRAG processing failed for document {doc_id}: {str(e)}")
            await self.metadata.update_document_status(doc_id, "graph_error", str(e))
    
    async def search_knowledge(
        self,
        query: str,
        search_type: str = "hybrid",
        user_id: str = None
    ) -> Dict[str, Any]:
        """çŸ¥è¯†æœç´¢"""
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"search:{hash(query)}:{search_type}"
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            return cached_result
        
        results = {}
        
        if search_type in ["hybrid", "graph"]:
            # GraphRAGæŸ¥è¯¢
            try:
                graph_results = await self.graphrag.query_graph(
                    query=query,
                    query_type="global"  # æˆ–æ ¹æ®æŸ¥è¯¢ç±»å‹æ™ºèƒ½é€‰æ‹©
                )
                results["graph_results"] = graph_results
            except Exception as e:
                self.logger.error(f"GraphRAG query error: {str(e)}")
                results["graph_error"] = str(e)
        
        if search_type in ["hybrid", "vector"]:
            # å‘é‡æœç´¢
            try:
                # è¿™é‡Œéœ€è¦è°ƒç”¨åµŒå…¥æœåŠ¡è·å–æŸ¥è¯¢å‘é‡
                query_embedding = await self._get_query_embedding(query)
                vector_results = await self.vector_db.search_similar(
                    collection_name="documents",
                    query_embedding=query_embedding,
                    n_results=10
                )
                results["vector_results"] = vector_results
            except Exception as e:
                self.logger.error(f"Vector search error: {str(e)}")
                results["vector_error"] = str(e)
        
        # ç¼“å­˜ç»“æœ
        await self.cache.set(cache_key, results, ttl=3600)  # 1å°æ—¶ç¼“å­˜
        
        return results
    
    async def get_document_status(self, doc_id: str) -> Dict[str, Any]:
        """è·å–æ–‡æ¡£å¤„ç†çŠ¶æ€"""
        return await self.metadata.get_document_metadata(doc_id)
    
    def _generate_doc_id(self) -> str:
        """ç”Ÿæˆæ–‡æ¡£ID"""
        import uuid
        return f"doc_{uuid.uuid4().hex[:12]}"
    
    def _extract_text_content(self, parsed_doc: Dict[str, Any]) -> str:
        """ä»è§£ææ–‡æ¡£ä¸­æå–æ–‡æœ¬å†…å®¹"""
        content_parts = []
        
        # æ·»åŠ æ ‡é¢˜
        if parsed_doc.get("title"):
            content_parts.append(parsed_doc["title"])
        
        # æ·»åŠ ç« èŠ‚å†…å®¹
        for section in parsed_doc.get("sections", []):
            if section.get("title"):
                content_parts.append(section["title"])
            content_parts.extend(section.get("content", []))
        
        # æ·»åŠ è¡¨æ ¼å†…å®¹
        for table in parsed_doc.get("tables", []):
            content_parts.append(table.get("content", ""))
        
        return "\n".join(content_parts)
    
    async def _get_query_embedding(self, query: str) -> List[float]:
        """è·å–æŸ¥è¯¢çš„åµŒå…¥å‘é‡"""
        # è¿™é‡Œè°ƒç”¨åµŒå…¥æœåŠ¡API
        # å¯ä»¥æ˜¯OpenAIã€Sentence Transformersç­‰
        pass
```

### 2. æŸ¥è¯¢å¼•æ“

```python
# src/core/knowledge/query_engine.py
from typing import Dict, List, Optional, Any
import asyncio

class QueryEngine:
    """è½»é‡åŒ–æŸ¥è¯¢å¼•æ“"""
    
    def __init__(self, knowledge_manager, cache_manager):
        self.knowledge_manager = knowledge_manager
        self.cache = cache_manager
    
    async def intelligent_search(
        self,
        query: str,
        context: Optional[Dict] = None,
        user_preferences: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """æ™ºèƒ½æœç´¢ - è‡ªåŠ¨é€‰æ‹©æœ€ä½³æœç´¢ç­–ç•¥"""
        
        # åˆ†ææŸ¥è¯¢ç±»å‹
        query_analysis = await self._analyze_query(query)
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©æœç´¢ç­–ç•¥
        if query_analysis["type"] == "factual":
            # äº‹å®æ€§æŸ¥è¯¢ï¼Œä¼˜å…ˆä½¿ç”¨GraphRAG
            search_type = "graph"
        elif query_analysis["type"] == "semantic":
            # è¯­ä¹‰æŸ¥è¯¢ï¼Œä½¿ç”¨å‘é‡æœç´¢
            search_type = "vector"
        else:
            # å¤åˆæŸ¥è¯¢ï¼Œä½¿ç”¨æ··åˆæœç´¢
            search_type = "hybrid"
        
        # æ‰§è¡Œæœç´¢
        results = await self.knowledge_manager.search_knowledge(
            query=query,
            search_type=search_type
        )
        
        # ç»“æœèåˆå’Œæ’åº
        fused_results = await self._fuse_results(results, query_analysis)
        
        return {
            "query": query,
            "query_type": query_analysis["type"],
            "search_strategy": search_type,
            "results": fused_results,
            "metadata": {
                "total_results": len(fused_results),
                "search_time": query_analysis.get("search_time"),
                "confidence": query_analysis.get("confidence")
            }
        }
    
    async def _analyze_query(self, query: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢ç±»å‹å’Œæ„å›¾"""
        # ç®€å•çš„æŸ¥è¯¢åˆ†æé€»è¾‘
        # åœ¨å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPåˆ†æ
        
        query_lower = query.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å®ä½“å…³ç³»è¯æ±‡
        relation_keywords = ["å…³ç³»", "è¿æ¥", "ç›¸å…³", "å½±å“", "å¯¼è‡´", "å…³è”"]
        if any(keyword in query_lower for keyword in relation_keywords):
            return {"type": "factual", "confidence": 0.8}
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¯­ä¹‰æœç´¢
        semantic_keywords = ["ç±»ä¼¼", "ç›¸ä¼¼", "åƒ", "ç›¸å…³æ–‡æ¡£"]
        if any(keyword in query_lower for keyword in semantic_keywords):
            return {"type": "semantic", "confidence": 0.7}
        
        # é»˜è®¤ä¸ºå¤åˆæŸ¥è¯¢
        return {"type": "hybrid", "confidence": 0.6}
    
    async def _fuse_results(
        self,
        results: Dict[str, Any],
        query_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """èåˆä¸åŒæ¥æºçš„æœç´¢ç»“æœ"""
        
        fused_results = []
        
        # å¤„ç†GraphRAGç»“æœ
        if "graph_results" in results:
            graph_data = results["graph_results"]
            if "results" in graph_data:
                graph_result = {
                    "source": "graphrag",
                    "type": "answer",
                    "content": graph_data["results"].get("answer", ""),
                    "confidence": 0.9,
                    "supporting_data": graph_data["results"].get("source_communities", [])
                }
                fused_results.append(graph_result)
        
        # å¤„ç†å‘é‡æœç´¢ç»“æœ
        if "vector_results" in results:
            vector_data = results["vector_results"]
            for i, (doc, distance, metadata) in enumerate(zip(
                vector_data.get("documents", [[]])[0],
                vector_data.get("distances", [[]])[0],
                vector_data.get("metadatas", [[]])[0]
            )):
                vector_result = {
                    "source": "vector_search",
                    "type": "document",
                    "content": doc,
                    "confidence": 1 - distance,  # è·ç¦»è¶Šå°ç½®ä¿¡åº¦è¶Šé«˜
                    "metadata": metadata,
                    "rank": i + 1
                }
                fused_results.append(vector_result)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        fused_results.sort(key=lambda x: x["confidence"], reverse=True)
        
        return fused_results[:10]  # è¿”å›å‰10ä¸ªç»“æœ
```

## ç¼“å­˜ç­–ç•¥è®¾è®¡

### æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨

```python
# src/core/knowledge/cache_manager.py
import redis
import json
import hashlib
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta

class CacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, redis_config: Dict[str, Any]):
        self.redis_client = redis.Redis(
            host=redis_config.get("host", "localhost"),
            port=redis_config.get("port", 6379),
            db=redis_config.get("db", 0),
            decode_responses=True
        )
        
        # ç¼“å­˜ç­–ç•¥é…ç½®
        self.cache_ttl = {
            "document_parsing": 86400 * 7,    # æ–‡æ¡£è§£æç»“æœç¼“å­˜7å¤©
            "graph_query": 3600,              # å›¾è°±æŸ¥è¯¢ç»“æœç¼“å­˜1å°æ—¶
            "vector_search": 1800,            # å‘é‡æœç´¢ç»“æœç¼“å­˜30åˆ†é’Ÿ
            "user_session": 86400,            # ç”¨æˆ·ä¼šè¯ç¼“å­˜1å¤©
        }
    
    async def get_document_result(self, filename: str, file_content: bytes) -> Optional[Dict]:
        """è·å–æ–‡æ¡£è§£æç»“æœç¼“å­˜"""
        content_hash = hashlib.md5(file_content).hexdigest()
        cache_key = f"doc_parse:{filename}:{content_hash}"
        
        cached_data = self.redis_client.get(cache_key)
        if cached_data:
            return json.loads(cached_data)
        return None
    
    async def cache_document_result(
        self,
        filename: str,
        file_content: bytes,
        result: Dict[str, Any]
    ):
        """ç¼“å­˜æ–‡æ¡£è§£æç»“æœ"""
        content_hash = hashlib.md5(file_content).hexdigest()
        cache_key = f"doc_parse:{filename}:{content_hash}"
        
        self.redis_client.setex(
            cache_key,
            self.cache_ttl["document_parsing"],
            json.dumps(result, ensure_ascii=False)
        )
    
    async def get(self, key: str) -> Optional[Any]:
        """é€šç”¨ç¼“å­˜è·å–"""
        cached_data = self.redis_client.get(key)
        if cached_data:
            return json.loads(cached_data)
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """é€šç”¨ç¼“å­˜è®¾ç½®"""
        if ttl:
            self.redis_client.setex(key, ttl, json.dumps(value, ensure_ascii=False))
        else:
            self.redis_client.set(key, json.dumps(value, ensure_ascii=False))
    
    async def invalidate_pattern(self, pattern: str):
        """æŒ‰æ¨¡å¼å¤±æ•ˆç¼“å­˜"""
        keys = self.redis_client.keys(pattern)
        if keys:
            self.redis_client.delete(*keys)
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        info = self.redis_client.info()
        return {
            "used_memory": info.get("used_memory_human"),
            "connected_clients": info.get("connected_clients"),
            "keyspace_hits": info.get("keyspace_hits"),
            "keyspace_misses": info.get("keyspace_misses"),
            "hit_rate": info.get("keyspace_hits", 0) / max(
                info.get("keyspace_hits", 0) + info.get("keyspace_misses", 0), 1
            )
        }
```

## æœåŠ¡ç¼–æ’å™¨

```python
# src/core/knowledge/service_orchestrator.py
from typing import Dict, List, Optional, Any
import asyncio
import logging
from enum import Enum

class ServiceStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"

class ServiceOrchestrator:
    """æœåŠ¡ç¼–æ’å™¨ - ç®¡ç†å¤–éƒ¨æœåŠ¡çš„è°ƒç”¨å’Œæ•…éšœå¤„ç†"""
    
    def __init__(self, services_config: Dict[str, Any]):
        self.services = {}
        self.service_status = {}
        self.circuit_breakers = {}
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–æœåŠ¡å®¢æˆ·ç«¯
        self._initialize_services(services_config)
    
    def _initialize_services(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–å¤–éƒ¨æœåŠ¡å®¢æˆ·ç«¯"""
        from .external.unstructured_client import UnstructuredClient
        from .external.graphrag_client import GraphRAGClient
        from .external.vector_db_client import VectorDBClient
        
        # åˆå§‹åŒ–UnstructuredæœåŠ¡
        if "unstructured" in config:
            self.services["unstructured"] = UnstructuredClient(config["unstructured"])
            self.service_status["unstructured"] = ServiceStatus.HEALTHY
        
        # åˆå§‹åŒ–GraphRAGæœåŠ¡
        if "graphrag" in config:
            self.services["graphrag"] = GraphRAGClient(config["graphrag"])
            self.service_status["graphrag"] = ServiceStatus.HEALTHY
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“æœåŠ¡
        if "vector_db" in config:
            self.services["vector_db"] = VectorDBClient(config["vector_db"])
            self.service_status["vector_db"] = ServiceStatus.HEALTHY
    
    async def call_service(
        self,
        service_name: str,
        method_name: str,
        *args,
        **kwargs
    ) -> Any:
        """è°ƒç”¨å¤–éƒ¨æœåŠ¡çš„æ–¹æ³•"""
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        if self.service_status.get(service_name) == ServiceStatus.UNHEALTHY:
            raise Exception(f"Service {service_name} is unhealthy")
        
        # æ£€æŸ¥ç†”æ–­å™¨
        if self._is_circuit_open(service_name):
            raise Exception(f"Circuit breaker is open for service {service_name}")
        
        try:
            service = self.services.get(service_name)
            if not service:
                raise Exception(f"Service {service_name} not found")
            
            method = getattr(service, method_name)
            result = await method(*args, **kwargs)
            
            # è°ƒç”¨æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°
            self._record_success(service_name)
            
            return result
            
        except Exception as e:
            # è®°å½•å¤±è´¥
            self._record_failure(service_name)
            self.logger.error(f"Service call failed: {service_name}.{method_name}, error: {str(e)}")
            raise
    
    async def health_check_all_services(self) -> Dict[str, ServiceStatus]:
        """æ£€æŸ¥æ‰€æœ‰æœåŠ¡å¥åº·çŠ¶æ€"""
        health_results = {}
        
        for service_name in self.services:
            try:
                health_status = await self._check_service_health(service_name)
                health_results[service_name] = health_status
                self.service_status[service_name] = health_status
            except Exception as e:
                self.logger.error(f"Health check failed for {service_name}: {str(e)}")
                health_results[service_name] = ServiceStatus.UNHEALTHY
                self.service_status[service_name] = ServiceStatus.UNHEALTHY
        
        return health_results
    
    async def _check_service_health(self, service_name: str) -> ServiceStatus:
        """æ£€æŸ¥å•ä¸ªæœåŠ¡å¥åº·çŠ¶æ€"""
        service = self.services.get(service_name)
        
        if service_name == "unstructured":
            # è°ƒç”¨å¥åº·æ£€æŸ¥æ¥å£
            try:
                # è¿™é‡Œå¯ä»¥è°ƒç”¨æœåŠ¡çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹
                return ServiceStatus.HEALTHY
            except:
                return ServiceStatus.UNHEALTHY
                
        elif service_name == "graphrag":
            # GraphRAGå¥åº·æ£€æŸ¥
            try:
                return ServiceStatus.HEALTHY
            except:
                return ServiceStatus.UNHEALTHY
                
        elif service_name == "vector_db":
            # å‘é‡æ•°æ®åº“å¥åº·æ£€æŸ¥
            try:
                return ServiceStatus.HEALTHY
            except:
                return ServiceStatus.UNHEALTHY
        
        return ServiceStatus.UNHEALTHY
    
    def _is_circuit_open(self, service_name: str) -> bool:
        """æ£€æŸ¥ç†”æ–­å™¨æ˜¯å¦å¼€å¯"""
        circuit = self.circuit_breakers.get(service_name, {"failures": 0, "last_failure": None})
        
        # ç®€å•çš„ç†”æ–­å™¨é€»è¾‘ï¼š5æ¬¡å¤±è´¥åå¼€å¯ç†”æ–­å™¨
        return circuit["failures"] >= 5
    
    def _record_success(self, service_name: str):
        """è®°å½•æœåŠ¡è°ƒç”¨æˆåŠŸ"""
        if service_name in self.circuit_breakers:
            self.circuit_breakers[service_name]["failures"] = 0
    
    def _record_failure(self, service_name: str):
        """è®°å½•æœåŠ¡è°ƒç”¨å¤±è´¥"""
        if service_name not in self.circuit_breakers:
            self.circuit_breakers[service_name] = {"failures": 0, "last_failure": None}
        
        self.circuit_breakers[service_name]["failures"] += 1
        self.circuit_breakers[service_name]["last_failure"] = asyncio.get_event_loop().time()
```

## ç³»ç»Ÿé…ç½®

### è½»é‡åŒ–ç³»ç»Ÿé…ç½®

```yaml
# config/lightweight_knowledge_system.yaml
system:
  name: "Lightweight Knowledge Management System"
  version: "1.0.0"
  mode: "lightweight"  # lightweight/full
  
# å¤–éƒ¨æœåŠ¡é…ç½®
external_services:
  # Unstructuredæ–‡æ¡£è§£ææœåŠ¡
  unstructured:
    api_url: "http://unstructured-api:8000"
    api_key: "${UNSTRUCTURED_API_KEY}"
    timeout: 300
    max_retries: 3
    
  # Microsoft GraphRAGæœåŠ¡
  graphrag:
    api_url: "http://graphrag-api:8001"
    api_key: "${GRAPHRAG_API_KEY}"
    timeout: 600
    
  # å‘é‡æ•°æ®åº“æœåŠ¡
  vector_db:
    type: "chroma"  # chroma/pinecone/weaviate
    host: "chroma-db"
    port: 8000
    
  # LLMæœåŠ¡
  llm_services:
    openai:
      api_key: "${OPENAI_API_KEY}"
      models: ["gpt-4", "gpt-3.5-turbo", "text-embedding-ada-002"]
    anthropic:
      api_key: "${ANTHROPIC_API_KEY}"
      models: ["claude-3-sonnet", "claude-3-haiku"]

# æ ¸å¿ƒç³»ç»Ÿé…ç½®
core:
  # ç¼“å­˜é…ç½®
  cache:
    redis:
      host: "redis"
      port: 6379
      db: 0
    ttl:
      document_parsing: 604800  # 7å¤©
      graph_query: 3600        # 1å°æ—¶
      vector_search: 1800      # 30åˆ†é’Ÿ
      
  # å…ƒæ•°æ®å­˜å‚¨
  metadata_store:
    type: "postgresql"
    host: "postgres"
    port: 5432
    database: "knowledge_metadata"
    username: "${POSTGRES_USER}"
    password: "${POSTGRES_PASSWORD}"
    
  # æ¶ˆæ¯é˜Ÿåˆ—
  message_queue:
    type: "redis"
    host: "redis"
    port: 6379
    db: 1

# APIé…ç½®
api:
  host: "0.0.0.0"
  port: 8080
  cors_enabled: true
  rate_limiting:
    enabled: true
    requests_per_minute: 100
    
# ç›‘æ§é…ç½®
monitoring:
  health_check:
    enabled: true
    interval: 30  # ç§’
  metrics:
    enabled: true
    prometheus_endpoint: "/metrics"
  logging:
    level: "INFO"
    format: "json"

# å®‰å…¨é…ç½®
security:
  authentication:
    enabled: true
    type: "jwt"
    secret_key: "${JWT_SECRET_KEY}"
  authorization:
    enabled: true
    default_role: "user"
```

## éƒ¨ç½²æ–¹æ¡ˆ

### Docker Composeéƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  # æˆ‘ä»¬çš„è½»é‡åŒ–çŸ¥è¯†åº“ç³»ç»Ÿ
  knowledge-system:
    build: .
    ports:
      - "8080:8080"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - UNSTRUCTURED_API_URL=http://unstructured:8000
      - GRAPHRAG_API_URL=http://graphrag:8001
      - CHROMA_HOST=chroma
    depends_on:
      - redis
      - postgres
      - unstructured
      - graphrag
      - chroma
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
      
  # Redisç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      
  # PostgreSQLå…ƒæ•°æ®å­˜å‚¨
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=knowledge_metadata
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  # Unstructuredæ–‡æ¡£è§£ææœåŠ¡
  unstructured:
    image: quay.io/unstructured-io/unstructured-api:latest
    ports:
      - "8000:8000"
    environment:
      - UNSTRUCTURED_API_KEY=${UNSTRUCTURED_API_KEY}
    deploy:
      resources:
        limits:
          memory: 4G
          
  # Microsoft GraphRAGæœåŠ¡
  graphrag:
    image: microsoft/graphrag:latest
    ports:
      - "8001:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GRAPHRAG_CONFIG_PATH=/app/config/graphrag.yaml
    volumes:
      - ./config/graphrag.yaml:/app/config/graphrag.yaml
    deploy:
      resources:
        limits:
          memory: 8G
          
  # Chromaå‘é‡æ•°æ®åº“
  chroma:
    image: chromadb/chroma:latest
    ports:
      - "8002:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000

volumes:
  redis_data:
  postgres_data:
  chroma_data:
```

## æ€»ç»“

è¿™ä¸ªè½»é‡åŒ–çŸ¥è¯†åº“ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

### ğŸ¯ **æ ¸å¿ƒä¼˜åŠ¿**

1. **ä¸“ä¸šåˆ†å·¥**ï¼šé«˜è€—èƒ½ä»»åŠ¡å¤–åŒ…ç»™ä¸“ä¸šæœåŠ¡ï¼Œæˆ‘ä»¬ä¸“æ³¨æ ¸å¿ƒä¸šåŠ¡
2. **è½»é‡é«˜æ•ˆ**ï¼šç³»ç»Ÿä¿æŒè½»é‡çº§ï¼Œå¯åŠ¨å¿«ï¼Œèµ„æºå ç”¨å°‘
3. **æ™ºèƒ½ç¼“å­˜**ï¼šå¤šå±‚ç¼“å­˜ç­–ç•¥ï¼Œå‡å°‘å¤–éƒ¨æœåŠ¡è°ƒç”¨
4. **æœåŠ¡ç¼–æ’**ï¼šç»Ÿä¸€ç®¡ç†å¤–éƒ¨æœåŠ¡ï¼Œæä¾›æ•…éšœå¤„ç†å’Œç†”æ–­æœºåˆ¶
5. **æ˜“äºæ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ·»åŠ æ–°çš„å¤–éƒ¨æœåŠ¡

### ğŸ”§ **æŠ€æœ¯ç‰¹è‰²**

1. **å¤–éƒ¨æœåŠ¡é›†æˆ**ï¼šUnstructured + GraphRAG + å¼€æºå‘é‡æ•°æ®åº“
2. **æ™ºèƒ½æŸ¥è¯¢å¼•æ“**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³æœç´¢ç­–ç•¥
3. **ç¼“å­˜ä¼˜åŒ–**ï¼šé’ˆå¯¹ä¸åŒç±»å‹æ•°æ®çš„å·®å¼‚åŒ–ç¼“å­˜ç­–ç•¥
4. **æ•…éšœå¤„ç†**ï¼šç†”æ–­å™¨ã€é‡è¯•æœºåˆ¶ã€é™çº§ç­–ç•¥
5. **ç›‘æ§å®Œå–„**ï¼šæœåŠ¡å¥åº·æ£€æŸ¥ã€æ€§èƒ½ç›‘æ§ã€æ—¥å¿—è®°å½•

### ğŸ“Š **èµ„æºä¼˜åŒ–**

- **CPUä½¿ç”¨**ï¼šä¸»è¦ç”¨äºAPIè°ƒç”¨å’Œç»“æœå¤„ç†ï¼ŒCPUå ç”¨ä½
- **å†…å­˜ä½¿ç”¨**ï¼šä¸»è¦ç”¨äºç¼“å­˜ï¼Œå¯æ§åˆ¶ç¼“å­˜å¤§å°
- **å­˜å‚¨éœ€æ±‚**ï¼šåªå­˜å‚¨å…ƒæ•°æ®å’Œç¼“å­˜ï¼Œå­˜å‚¨éœ€æ±‚å°
- **ç½‘ç»œå¸¦å®½**ï¼šä¸»è¦æ˜¯APIè°ƒç”¨ï¼Œå¸¦å®½éœ€æ±‚é€‚ä¸­

è¿™ä¸ªæ–¹æ¡ˆè®©æˆ‘ä»¬èƒ½å¤Ÿä»¥æœ€å°çš„èµ„æºæŠ•å…¥ï¼Œè·å¾—æœ€å¤§çš„åŠŸèƒ½ä»·å€¼ï¼ŒåŒæ—¶ä¿æŒç³»ç»Ÿçš„é«˜æ€§èƒ½å’Œå¯æ‰©å±•æ€§ï¼

## APIæ¥å£è®¾è®¡

### RESTful APIè§„èŒƒ

```python
# src/communication/knowledge/api_gateway.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Optional, Dict, Any
import asyncio

app = FastAPI(
    title="Lightweight Knowledge Management API",
    description="è½»é‡åŒ–çŸ¥è¯†åº“ç®¡ç†ç³»ç»ŸAPI",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class KnowledgeAPI:
    """çŸ¥è¯†åº“APIç½‘å…³"""
    
    def __init__(self, knowledge_manager, query_engine, service_orchestrator):
        self.knowledge_manager = knowledge_manager
        self.query_engine = query_engine
        self.service_orchestrator = service_orchestrator

# æ–‡æ¡£ç®¡ç†API
@app.post("/api/v1/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    user_id: str = "default"
):
    """ä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£"""
    try:
        file_content = await file.read()
        result = await knowledge_manager.process_document(
            file_content=file_content,
            filename=file.filename,
            user_id=user_id
        )
        return {
            "success": True,
            "data": result,
            "message": "Document uploaded and processing started"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/documents/{doc_id}/status")
async def get_document_status(doc_id: str):
    """è·å–æ–‡æ¡£å¤„ç†çŠ¶æ€"""
    try:
        status = await knowledge_manager.get_document_status(doc_id)
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        raise HTTPException(status_code=404, detail="Document not found")

@app.post("/api/v1/documents/batch_upload")
async def batch_upload_documents(
    files: List[UploadFile] = File(...),
    user_id: str = "default"
):
    """æ‰¹é‡ä¸Šä¼ æ–‡æ¡£"""
    results = []
    
    for file in files:
        try:
            file_content = await file.read()
            result = await knowledge_manager.process_document(
                file_content=file_content,
                filename=file.filename,
                user_id=user_id
            )
            results.append({
                "filename": file.filename,
                "success": True,
                "doc_id": result["doc_id"]
            })
        except Exception as e:
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
    
    return {
        "success": True,
        "data": {
            "total_files": len(files),
            "successful": len([r for r in results if r["success"]]),
            "failed": len([r for r in results if not r["success"]]),
            "results": results
        }
    }

# çŸ¥è¯†æœç´¢API
@app.post("/api/v1/search")
async def search_knowledge(
    query: str,
    search_type: str = "hybrid",  # hybrid/graph/vector
    max_results: int = 10,
    user_id: str = "default"
):
    """æ™ºèƒ½çŸ¥è¯†æœç´¢"""
    try:
        results = await query_engine.intelligent_search(
            query=query,
            context={"search_type": search_type, "max_results": max_results}
        )
        return {
            "success": True,
            "data": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/search/graph")
async def graph_search(
    query: str,
    query_type: str = "global",  # global/local
    max_tokens: int = 4000
):
    """GraphRAGä¸“ç”¨æœç´¢"""
    try:
        result = await service_orchestrator.call_service(
            "graphrag",
            "query_graph",
            query=query,
            query_type=query_type,
            config={"max_tokens": max_tokens}
        )
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/search/vector")
async def vector_search(
    query: str,
    collection_name: str = "documents",
    n_results: int = 10
):
    """å‘é‡ç›¸ä¼¼æ€§æœç´¢"""
    try:
        # è·å–æŸ¥è¯¢å‘é‡
        query_embedding = await get_query_embedding(query)
        
        result = await service_orchestrator.call_service(
            "vector_db",
            "search_similar",
            collection_name=collection_name,
            query_embedding=query_embedding,
            n_results=n_results
        )
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ç³»ç»Ÿç®¡ç†API
@app.get("/api/v1/system/health")
async def system_health():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    try:
        health_status = await service_orchestrator.health_check_all_services()
        cache_stats = await cache_manager.get_cache_stats()
        
        return {
            "success": True,
            "data": {
                "services": health_status,
                "cache": cache_stats,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/system/stats")
async def system_statistics():
    """ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è·å–å„ç§ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "documents": {
                "total": await metadata_store.count_documents(),
                "processed": await metadata_store.count_processed_documents(),
                "processing": await metadata_store.count_processing_documents()
            },
            "cache": await cache_manager.get_cache_stats(),
            "services": await service_orchestrator.health_check_all_services()
        }
        
        return {
            "success": True,
            "data": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# WebSocketæ”¯æŒå®æ—¶é€šçŸ¥
@app.websocket("/ws/notifications")
async def websocket_notifications(websocket: WebSocket):
    """WebSocketå®æ—¶é€šçŸ¥"""
    await websocket.accept()
    
    try:
        while True:
            # å‘é€ç³»ç»ŸçŠ¶æ€æ›´æ–°
            status_update = await get_system_status_update()
            await websocket.send_json(status_update)
            await asyncio.sleep(5)  # æ¯5ç§’å‘é€ä¸€æ¬¡æ›´æ–°
            
    except Exception as e:
        await websocket.close()
```

## ç”¨æˆ·ç•Œé¢è®¾è®¡

### Web Dashboardç•Œé¢

```typescript
// frontend/src/components/KnowledgeManager.tsx
import React, { useState, useEffect } from 'react';
import { Upload, Search, FileText, BarChart3, Settings } from 'lucide-react';

interface Document {
  doc_id: string;
  filename: string;
  status: 'parsing' | 'processing' | 'completed' | 'error';
  created_at: string;
  progress?: number;
}

interface SearchResult {
  source: string;
  type: string;
  content: string;
  confidence: number;
  metadata?: any;
}

const KnowledgeManager: React.FC = () => {
  const [documents, setDocuments] = useState<Document[]>([]);
  const [searchQuery, setSearchQuery] = useState('');
  const [searchResults, setSearchResults] = useState<SearchResult[]>([]);
  const [systemStats, setSystemStats] = useState<any>({});
  const [isUploading, setIsUploading] = useState(false);

  // æ–‡æ¡£ä¸Šä¼ ç»„ä»¶
  const DocumentUpload = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <Upload className="mr-2" />
        æ–‡æ¡£ä¸Šä¼ 
      </h2>
      
      <div className="border-2 border-dashed border-gray-300 rounded-lg p-8 text-center">
        <input
          type="file"
          multiple
          accept=".pdf,.docx,.xlsx,.pptx,.txt,.md"
          onChange={handleFileUpload}
          className="hidden"
          id="file-upload"
        />
        <label
          htmlFor="file-upload"
          className="cursor-pointer flex flex-col items-center"
        >
          <FileText className="w-12 h-12 text-gray-400 mb-4" />
          <p className="text-lg font-medium">ç‚¹å‡»ä¸Šä¼ æ–‡æ¡£</p>
          <p className="text-sm text-gray-500">
            æ”¯æŒ PDF, Word, Excel, PowerPoint, æ–‡æœ¬æ–‡ä»¶
          </p>
        </label>
      </div>
      
      {isUploading && (
        <div className="mt-4">
          <div className="bg-blue-100 border border-blue-400 text-blue-700 px-4 py-3 rounded">
            æ­£åœ¨ä¸Šä¼ å’Œå¤„ç†æ–‡æ¡£...
          </div>
        </div>
      )}
    </div>
  );

  // æ™ºèƒ½æœç´¢ç»„ä»¶
  const IntelligentSearch = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <Search className="mr-2" />
        æ™ºèƒ½æœç´¢
      </h2>
      
      <div className="flex space-x-4 mb-4">
        <input
          type="text"
          value={searchQuery}
          onChange={(e) => setSearchQuery(e.target.value)}
          placeholder="è¾“å…¥æœç´¢é—®é¢˜..."
          className="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500"
          onKeyPress={(e) => e.key === 'Enter' && handleSearch()}
        />
        <button
          onClick={handleSearch}
          className="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700"
        >
          æœç´¢
        </button>
      </div>
      
      <div className="flex space-x-2 mb-4">
        <button className="px-3 py-1 bg-gray-200 rounded-full text-sm">
          æ··åˆæœç´¢
        </button>
        <button className="px-3 py-1 bg-gray-200 rounded-full text-sm">
          å›¾è°±æœç´¢
        </button>
        <button className="px-3 py-1 bg-gray-200 rounded-full text-sm">
          å‘é‡æœç´¢
        </button>
      </div>
      
      {searchResults.length > 0 && (
        <div className="space-y-4">
          {searchResults.map((result, index) => (
            <div key={index} className="border border-gray-200 rounded-lg p-4">
              <div className="flex justify-between items-start mb-2">
                <span className="px-2 py-1 bg-blue-100 text-blue-800 rounded text-xs">
                  {result.source}
                </span>
                <span className="text-sm text-gray-500">
                  ç½®ä¿¡åº¦: {(result.confidence * 100).toFixed(1)}%
                </span>
              </div>
              <p className="text-gray-800">{result.content}</p>
            </div>
          ))}
        </div>
      )}
    </div>
  );

  // æ–‡æ¡£çŠ¶æ€ç›‘æ§
  const DocumentStatus = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <FileText className="mr-2" />
        æ–‡æ¡£çŠ¶æ€
      </h2>
      
      <div className="space-y-3">
        {documents.map((doc) => (
          <div key={doc.doc_id} className="flex justify-between items-center p-3 border border-gray-200 rounded">
            <div>
              <p className="font-medium">{doc.filename}</p>
              <p className="text-sm text-gray-500">{doc.created_at}</p>
            </div>
            <div className="text-right">
              <StatusBadge status={doc.status} />
              {doc.progress && (
                <div className="w-24 bg-gray-200 rounded-full h-2 mt-1">
                  <div
                    className="bg-blue-600 h-2 rounded-full"
                    style={{ width: `${doc.progress}%` }}
                  ></div>
                </div>
              )}
            </div>
          </div>
        ))}
      </div>
    </div>
  );

  // ç³»ç»Ÿç›‘æ§é¢æ¿
  const SystemDashboard = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <BarChart3 className="mr-2" />
        ç³»ç»Ÿç›‘æ§
      </h2>
      
      <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
        <div className="text-center">
          <p className="text-2xl font-bold text-blue-600">
            {systemStats.documents?.total || 0}
          </p>
          <p className="text-sm text-gray-500">æ€»æ–‡æ¡£æ•°</p>
        </div>
        <div className="text-center">
          <p className="text-2xl font-bold text-green-600">
            {systemStats.documents?.processed || 0}
          </p>
          <p className="text-sm text-gray-500">å·²å¤„ç†</p>
        </div>
        <div className="text-center">
          <p className="text-2xl font-bold text-yellow-600">
            {systemStats.documents?.processing || 0}
          </p>
          <p className="text-sm text-gray-500">å¤„ç†ä¸­</p>
        </div>
        <div className="text-center">
          <p className="text-2xl font-bold text-purple-600">
            {((systemStats.cache?.hit_rate || 0) * 100).toFixed(1)}%
          </p>
          <p className="text-sm text-gray-500">ç¼“å­˜å‘½ä¸­ç‡</p>
        </div>
      </div>
      
      <div className="mt-6">
        <h3 className="font-medium mb-2">å¤–éƒ¨æœåŠ¡çŠ¶æ€</h3>
        <div className="space-y-2">
          {Object.entries(systemStats.services || {}).map(([service, status]) => (
            <div key={service} className="flex justify-between items-center">
              <span className="capitalize">{service}</span>
              <ServiceStatusBadge status={status as string} />
            </div>
          ))}
        </div>
      </div>
    </div>
  );

  // äº‹ä»¶å¤„ç†å‡½æ•°
  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files) return;

    setIsUploading(true);
    
    const formData = new FormData();
    Array.from(files).forEach(file => formData.append('files', file));
    
    try {
      const response = await fetch('/api/v1/documents/batch_upload', {
        method: 'POST',
        body: formData,
      });
      
      const result = await response.json();
      if (result.success) {
        // åˆ·æ–°æ–‡æ¡£åˆ—è¡¨
        fetchDocuments();
      }
    } catch (error) {
      console.error('Upload failed:', error);
    } finally {
      setIsUploading(false);
    }
  };

  const handleSearch = async () => {
    if (!searchQuery.trim()) return;
    
    try {
      const response = await fetch('/api/v1/search', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: searchQuery }),
      });
      
      const result = await response.json();
      if (result.success) {
        setSearchResults(result.data.results);
      }
    } catch (error) {
      console.error('Search failed:', error);
    }
  };

  const fetchDocuments = async () => {
    // è·å–æ–‡æ¡£åˆ—è¡¨çš„é€»è¾‘
  };

  const fetchSystemStats = async () => {
    try {
      const response = await fetch('/api/v1/system/stats');
      const result = await response.json();
      if (result.success) {
        setSystemStats(result.data);
      }
    } catch (error) {
      console.error('Failed to fetch system stats:', error);
    }
  };

  useEffect(() => {
    fetchDocuments();
    fetchSystemStats();
    
    // è®¾ç½®å®šæ—¶åˆ·æ–°
    const interval = setInterval(fetchSystemStats, 30000); // 30ç§’åˆ·æ–°ä¸€æ¬¡
    return () => clearInterval(interval);
  }, []);

  return (
    <div className="min-h-screen bg-gray-100">
      <header className="bg-white shadow">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="flex justify-between items-center py-6">
            <h1 className="text-3xl font-bold text-gray-900">
              è½»é‡åŒ–çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ
            </h1>
            <Settings className="w-6 h-6 text-gray-500 cursor-pointer" />
          </div>
        </div>
      </header>
      
      <main className="max-w-7xl mx-auto py-6 px-4 sm:px-6 lg:px-8">
        <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
          <DocumentUpload />
          <IntelligentSearch />
          <DocumentStatus />
          <SystemDashboard />
        </div>
      </main>
    </div>
  );
};

// è¾…åŠ©ç»„ä»¶
const StatusBadge: React.FC<{ status: string }> = ({ status }) => {
  const colors = {
    parsing: 'bg-yellow-100 text-yellow-800',
    processing: 'bg-blue-100 text-blue-800',
    completed: 'bg-green-100 text-green-800',
    error: 'bg-red-100 text-red-800',
  };
  
  return (
    <span className={`px-2 py-1 rounded-full text-xs ${colors[status as keyof typeof colors]}`}>
      {status}
    </span>
  );
};

const ServiceStatusBadge: React.FC<{ status: string }> = ({ status }) => {
  const colors = {
    healthy: 'bg-green-100 text-green-800',
    degraded: 'bg-yellow-100 text-yellow-800',
    unhealthy: 'bg-red-100 text-red-800',
  };
  
  return (
    <span className={`px-2 py-1 rounded-full text-xs ${colors[status as keyof typeof colors]}`}>
      {status}
    </span>
  );
};

export default KnowledgeManager;
```

## å®æ–½è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¶æ„æ­å»ºï¼ˆ2å‘¨ï¼‰

#### Week 1: æ ¸å¿ƒæ¡†æ¶æ­å»º
```bash
Day 1-2: é¡¹ç›®åˆå§‹åŒ–
- åˆ›å»ºé¡¹ç›®ç»“æ„
- é…ç½®å¼€å‘ç¯å¢ƒ
- è®¾ç½®åŸºç¡€ä¾èµ–

Day 3-4: å¤–éƒ¨æœåŠ¡å®¢æˆ·ç«¯å¼€å‘
- UnstructuredClientå®ç°
- GraphRAGClientå®ç°
- VectorDBClientå®ç°

Day 5-7: æ ¸å¿ƒä¸šåŠ¡å±‚å¼€å‘
- KnowledgeManageråŸºç¡€åŠŸèƒ½
- ServiceOrchestratorå®ç°
- CacheManagerå®ç°
```

#### Week 2: APIå’Œå­˜å‚¨å±‚
```bash
Day 8-10: APIç½‘å…³å¼€å‘
- FastAPIåº”ç”¨æ­å»º
- åŸºç¡€APIæ¥å£å®ç°
- é”™è¯¯å¤„ç†å’ŒéªŒè¯

Day 11-12: æ•°æ®å­˜å‚¨å±‚
- PostgreSQLå…ƒæ•°æ®å­˜å‚¨
- Redisç¼“å­˜é…ç½®
- æ•°æ®æ¨¡å‹è®¾è®¡

Day 13-14: é›†æˆæµ‹è¯•
- æœåŠ¡é›†æˆæµ‹è¯•
- APIæ¥å£æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•
```

### ç¬¬äºŒé˜¶æ®µï¼šåŠŸèƒ½å®Œå–„ï¼ˆ2å‘¨ï¼‰

#### Week 3: é«˜çº§åŠŸèƒ½å¼€å‘
```bash
Day 15-17: æŸ¥è¯¢å¼•æ“ä¼˜åŒ–
- æ™ºèƒ½æŸ¥è¯¢åˆ†æ
- ç»“æœèåˆç®—æ³•
- æœç´¢ç­–ç•¥ä¼˜åŒ–

Day 18-19: ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- å¤šçº§ç¼“å­˜å®ç°
- ç¼“å­˜å¤±æ•ˆç­–ç•¥
- æ€§èƒ½ç›‘æ§

Day 20-21: ç›‘æ§å’Œå¥åº·æ£€æŸ¥
- æœåŠ¡å¥åº·æ£€æŸ¥
- æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- å‘Šè­¦æœºåˆ¶
```

#### Week 4: ç”¨æˆ·ç•Œé¢å¼€å‘
```bash
Day 22-24: å‰ç«¯ç•Œé¢å¼€å‘
- Reactç»„ä»¶å®ç°
- å®æ—¶çŠ¶æ€æ›´æ–°
- ç”¨æˆ·äº¤äº’ä¼˜åŒ–

Day 25-26: ç³»ç»Ÿé›†æˆ
- å‰åç«¯é›†æˆ
- WebSocketå®æ—¶é€šä¿¡
- å®Œæ•´æµç¨‹æµ‹è¯•

Day 27-28: éƒ¨ç½²å’Œä¼˜åŒ–
- Dockerå®¹å™¨åŒ–
- éƒ¨ç½²è„šæœ¬ç¼–å†™
- æ€§èƒ½è°ƒä¼˜
```

### ç¬¬ä¸‰é˜¶æ®µï¼šæµ‹è¯•å’Œéƒ¨ç½²ï¼ˆ1å‘¨ï¼‰

#### Week 5: æµ‹è¯•å’Œä¸Šçº¿
```bash
Day 29-30: å‹åŠ›æµ‹è¯•
- å¹¶å‘æ€§èƒ½æµ‹è¯•
- å¤§æ–‡ä»¶å¤„ç†æµ‹è¯•
- ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•

Day 31-32: å®‰å…¨æµ‹è¯•
- APIå®‰å…¨æµ‹è¯•
- æ•°æ®å®‰å…¨éªŒè¯
- æƒé™æ§åˆ¶æµ‹è¯•

Day 33-35: éƒ¨ç½²ä¸Šçº¿
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- ç›‘æ§é…ç½®
- æ–‡æ¡£å®Œå–„
```

## æˆæœ¬æ•ˆç›Šåˆ†æ

### èµ„æºéœ€æ±‚å¯¹æ¯”

| ç»„ä»¶ | ä¼ ç»Ÿæ–¹æ¡ˆ | è½»é‡åŒ–æ–¹æ¡ˆ | èŠ‚çœæ¯”ä¾‹ |
|------|----------|------------|----------|
| CPUæ ¸å¿ƒ | 16-32æ ¸ | 4-8æ ¸ | 50-75% |
| å†…å­˜ | 32-64GB | 8-16GB | 50-75% |
| å­˜å‚¨ | 1-5TB | 100-500GB | 80-90% |
| GPU | éœ€è¦ | ä¸éœ€è¦ | 100% |

### å¼€å‘æˆæœ¬å¯¹æ¯”

| é¡¹ç›® | ä¼ ç»Ÿæ–¹æ¡ˆ | è½»é‡åŒ–æ–¹æ¡ˆ | èŠ‚çœ |
|------|----------|------------|------|
| å¼€å‘æ—¶é—´ | 6-12ä¸ªæœˆ | 1-2ä¸ªæœˆ | 70-80% |
| å›¢é˜Ÿè§„æ¨¡ | 8-12äºº | 3-5äºº | 50-60% |
| æŠ€æœ¯å¤æ‚åº¦ | é«˜ | ä¸­ | - |
| ç»´æŠ¤æˆæœ¬ | é«˜ | ä½ | 60-70% |

### è¿è¥ä¼˜åŠ¿

1. **å¿«é€Ÿä¸Šçº¿**ï¼š1-2ä¸ªæœˆå³å¯æŠ•å…¥ä½¿ç”¨
2. **ä½ç»´æŠ¤æˆæœ¬**ï¼šä¸“ä¸šæœåŠ¡ç”±ä¾›åº”å•†ç»´æŠ¤
3. **å¼¹æ€§æ‰©å±•**ï¼šæ ¹æ®éœ€æ±‚è°ƒæ•´å¤–éƒ¨æœåŠ¡è§„æ¨¡
4. **æŠ€æœ¯æ›´æ–°**ï¼šè‡ªåŠ¨è·å¾—å¤–éƒ¨æœåŠ¡çš„æŠ€æœ¯å‡çº§
5. **é£é™©åˆ†æ•£**ï¼šé™ä½æŠ€æœ¯é£é™©å’Œç»´æŠ¤è´Ÿæ‹…

è¿™ä¸ªè½»é‡åŒ–æ–¹æ¡ˆè®©æˆ‘ä»¬èƒ½å¤Ÿä»¥æœ€å°çš„æŠ•å…¥ï¼Œå¿«é€Ÿæ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´ã€æ€§èƒ½ä¼˜è‰¯çš„çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿï¼ 