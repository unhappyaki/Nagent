# 轻量化知识库系统设计方案

## 项目概述

本方案设计了一个轻量化的知识库管理系统，将高耗能的文档解析和知识图谱生成任务外包给专业的外部服务，我们的系统专注于核心的查询、管理、缓存和用户交互功能。

### 设计理念
- **专业分工**：将复杂任务交给专业服务处理
- **轻量高效**：系统保持轻量级，专注核心功能
- **服务编排**：通过API编排各种外部服务
- **智能缓存**：减少外部服务调用，提升响应速度
- **用户体验**：提供统一、流畅的用户交互界面

## 整体架构设计

### 系统分层架构

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           User Interface Layer 用户界面层                        │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │ Web Dashboard   │  │ API Gateway     │  │ Chat Interface  │  │ Admin Panel     │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        Core Business Layer 核心业务层                            │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │ Query Engine    │  │ Knowledge       │  │ Service         │  │ Session         │ │
│  │                 │  │ Manager         │  │ Orchestrator    │  │ Manager         │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────────────────────────────┐
│                      Service Integration Layer 服务集成层                        │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │ External        │  │ Cache           │  │ Message         │  │ Health          │ │
│  │ Service Client  │  │ Manager         │  │ Queue           │  │ Monitor         │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────────────────────────────┐
│                         Data Storage Layer 数据存储层                            │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │ Metadata Store  │  │ Cache Store     │  │ Session Store   │  │ Config Store    │ │
│  │ (PostgreSQL)    │  │ (Redis)         │  │ (Redis)         │  │ (Local/Consul)  │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        External Services 外部服务层                              │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │ Unstructured    │  │ Microsoft       │  │ Vector DB       │  │ LLM Services    │ │
│  │ (文档解析)       │  │ GraphRAG        │  │ (Chroma/Pinecone)│  │ (OpenAI/Claude) │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────┘
```

## 外部服务集成策略

### 1. 文档解析服务 - Unstructured

```python
# src/core/knowledge/external/unstructured_client.py
from typing import Dict, List, Optional, Any
import aiohttp
import asyncio
from datetime import datetime

class UnstructuredClient:
    """Unstructured文档解析服务客户端"""
    
    def __init__(self, config: Dict[str, Any]):
        self.api_url = config.get("api_url", "http://unstructured:8000")
        self.api_key = config.get("api_key")
        self.timeout = config.get("timeout", 300)
        self.max_retries = config.get("max_retries", 3)
        
    async def parse_document(
        self,
        file_content: bytes,
        filename: str,
        parsing_strategy: str = "hi_res"
    ) -> Dict[str, Any]:
        """解析文档"""
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
            data = aiohttp.FormData()
            data.add_field('files', file_content, filename=filename)
            data.add_field('strategy', parsing_strategy)
            data.add_field('extract_images_in_pdf', 'true')
            data.add_field('infer_table_structure', 'true')
            data.add_field('ocr_languages', 'eng,chi_sim')
            
            headers = {}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
            
            for attempt in range(self.max_retries):
                try:
                    async with session.post(
                        f"{self.api_url}/general/v0/general",
                        data=data,
                        headers=headers
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            return self._process_unstructured_response(result)
                        else:
                            error_text = await response.text()
                            raise Exception(f"Unstructured API error: {response.status}, {error_text}")
                            
                except Exception as e:
                    if attempt == self.max_retries - 1:
                        raise
                    await asyncio.sleep(2 ** attempt)  # 指数退避
        
    def _process_unstructured_response(self, response: List[Dict]) -> Dict[str, Any]:
        """处理Unstructured响应"""
        processed_doc = {
            "title": "",
            "sections": [],
            "tables": [],
            "images": [],
            "metadata": {
                "total_elements": len(response),
                "parsed_at": datetime.utcnow().isoformat()
            }
        }
        
        current_section = None
        
        for element in response:
            element_type = element.get("type", "")
            text = element.get("text", "").strip()
            
            if element_type == "Title" and not processed_doc["title"]:
                processed_doc["title"] = text
                
            elif element_type in ["Title", "Header"]:
                current_section = {
                    "title": text,
                    "content": [],
                    "level": self._get_header_level(element)
                }
                processed_doc["sections"].append(current_section)
                
            elif element_type == "Table":
                processed_doc["tables"].append({
                    "content": text,
                    "html": element.get("metadata", {}).get("text_as_html", ""),
                    "page_number": element.get("metadata", {}).get("page_number")
                })
                
            elif element_type in ["NarrativeText", "ListItem", "Text"]:
                if current_section:
                    current_section["content"].append(text)
                else:
                    if not processed_doc["sections"]:
                        processed_doc["sections"].append({
                            "title": "Content",
                            "content": [],
                            "level": 1
                        })
                    processed_doc["sections"][0]["content"].append(text)
        
        return processed_doc
    
    def _get_header_level(self, element: Dict) -> int:
        """推断标题层级"""
        metadata = element.get("metadata", {})
        # 可以根据字体大小、样式等推断层级
        return metadata.get("header_level", 1)
```

### 2. 知识图谱服务 - Microsoft GraphRAG

```python
# src/core/knowledge/external/graphrag_client.py
from typing import Dict, List, Optional, Any
import aiohttp
import asyncio

class GraphRAGClient:
    """Microsoft GraphRAG服务客户端"""
    
    def __init__(self, config: Dict[str, Any]):
        self.api_url = config.get("api_url", "http://graphrag:8001")
        self.api_key = config.get("api_key")
        self.timeout = config.get("timeout", 600)  # GraphRAG处理时间较长
        
    async def build_knowledge_graph(
        self,
        documents: List[Dict[str, Any]],
        config: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """构建知识图谱"""
        
        payload = {
            "documents": documents,
            "config": config or {
                "chunk_size": 300,
                "chunk_overlap": 100,
                "community_algorithm": "leiden",
                "entity_extraction_model": "gpt-4",
                "relation_extraction_model": "gpt-4",
                "community_summarization_model": "gpt-4"
            }
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
                
            async with session.post(
                f"{self.api_url}/api/v1/build_graph",
                json=payload,
                headers=headers
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    error_text = await response.text()
                    raise Exception(f"GraphRAG API error: {response.status}, {error_text}")
    
    async def query_graph(
        self,
        query: str,
        query_type: str = "global",
        config: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """查询知识图谱"""
        
        payload = {
            "query": query,
            "query_type": query_type,  # global/local
            "config": config or {
                "max_tokens": 4000,
                "community_level": 2,
                "max_depth": 2
            }
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
                
            async with session.post(
                f"{self.api_url}/api/v1/query",
                json=payload,
                headers=headers
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    error_text = await response.text()
                    raise Exception(f"GraphRAG query error: {response.status}, {error_text}")
    
    async def get_graph_status(self, graph_id: str) -> Dict[str, Any]:
        """获取图谱构建状态"""
        
        async with aiohttp.ClientSession() as session:
            headers = {}
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
                
            async with session.get(
                f"{self.api_url}/api/v1/graphs/{graph_id}/status",
                headers=headers
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    return {"status": "error", "message": await response.text()}
```

### 3. 向量数据库服务 - 开源方案

```python
# src/core/knowledge/external/vector_db_client.py
from typing import Dict, List, Optional, Any
import chromadb
from chromadb.config import Settings

class VectorDBClient:
    """向量数据库客户端（支持Chroma、Pinecone等）"""
    
    def __init__(self, config: Dict[str, Any]):
        self.db_type = config.get("type", "chroma")
        self.config = config
        
        if self.db_type == "chroma":
            self.client = chromadb.HttpClient(
                host=config.get("host", "localhost"),
                port=config.get("port", 8000),
                settings=Settings(allow_reset=True)
            )
        elif self.db_type == "pinecone":
            import pinecone
            pinecone.init(
                api_key=config.get("api_key"),
                environment=config.get("environment")
            )
            self.client = pinecone
        
    async def create_collection(self, collection_name: str, metadata: Optional[Dict] = None):
        """创建集合"""
        if self.db_type == "chroma":
            return self.client.create_collection(
                name=collection_name,
                metadata=metadata or {}
            )
    
    async def add_documents(
        self,
        collection_name: str,
        documents: List[str],
        embeddings: List[List[float]],
        metadatas: List[Dict],
        ids: List[str]
    ):
        """添加文档"""
        if self.db_type == "chroma":
            collection = self.client.get_collection(collection_name)
            collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
    
    async def search_similar(
        self,
        collection_name: str,
        query_embedding: List[float],
        n_results: int = 10,
        where: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """相似性搜索"""
        if self.db_type == "chroma":
            collection = self.client.get_collection(collection_name)
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where
            )
            return results
```

## 核心业务层设计

### 1. 知识管理器

```python
# src/core/knowledge/knowledge_manager.py
from typing import Dict, List, Optional, Any
import asyncio
import logging
from datetime import datetime

class KnowledgeManager:
    """轻量化知识管理器 - 专注于服务编排和缓存"""
    
    def __init__(
        self,
        unstructured_client,
        graphrag_client,
        vector_db_client,
        cache_manager,
        metadata_store
    ):
        self.unstructured = unstructured_client
        self.graphrag = graphrag_client
        self.vector_db = vector_db_client
        self.cache = cache_manager
        self.metadata = metadata_store
        
        self.logger = logging.getLogger(__name__)
    
    async def process_document(
        self,
        file_content: bytes,
        filename: str,
        user_id: str
    ) -> Dict[str, Any]:
        """处理文档的完整流程"""
        
        doc_id = self._generate_doc_id()
        
        try:
            # 1. 检查缓存
            cached_result = await self.cache.get_document_result(filename, file_content)
            if cached_result:
                self.logger.info(f"Document {filename} found in cache")
                return cached_result
            
            # 2. 调用Unstructured解析文档
            self.logger.info(f"Parsing document {filename} with Unstructured")
            parsed_doc = await self.unstructured.parse_document(
                file_content=file_content,
                filename=filename
            )
            
            # 3. 保存解析结果到元数据存储
            await self.metadata.save_document_metadata(doc_id, {
                "filename": filename,
                "user_id": user_id,
                "parsed_at": datetime.utcnow().isoformat(),
                "status": "parsed",
                "sections_count": len(parsed_doc.get("sections", [])),
                "tables_count": len(parsed_doc.get("tables", [])),
                "images_count": len(parsed_doc.get("images", []))
            })
            
            # 4. 异步启动GraphRAG处理
            asyncio.create_task(self._process_with_graphrag(doc_id, parsed_doc))
            
            # 5. 缓存结果
            result = {
                "doc_id": doc_id,
                "status": "processing",
                "parsed_content": parsed_doc,
                "message": "Document parsed successfully, knowledge graph generation in progress"
            }
            
            await self.cache.cache_document_result(filename, file_content, result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"Error processing document {filename}: {str(e)}")
            await self.metadata.update_document_status(doc_id, "error", str(e))
            raise
    
    async def _process_with_graphrag(self, doc_id: str, parsed_doc: Dict[str, Any]):
        """异步处理GraphRAG"""
        try:
            # 准备GraphRAG输入
            documents = [{
                "doc_id": doc_id,
                "content": self._extract_text_content(parsed_doc),
                "metadata": parsed_doc.get("metadata", {})
            }]
            
            # 调用GraphRAG构建知识图谱
            graph_result = await self.graphrag.build_knowledge_graph(documents)
            
            # 更新状态
            await self.metadata.update_document_status(doc_id, "completed")
            await self.metadata.save_graph_metadata(doc_id, graph_result)
            
            self.logger.info(f"GraphRAG processing completed for document {doc_id}")
            
        except Exception as e:
            self.logger.error(f"GraphRAG processing failed for document {doc_id}: {str(e)}")
            await self.metadata.update_document_status(doc_id, "graph_error", str(e))
    
    async def search_knowledge(
        self,
        query: str,
        search_type: str = "hybrid",
        user_id: str = None
    ) -> Dict[str, Any]:
        """知识搜索"""
        
        # 检查缓存
        cache_key = f"search:{hash(query)}:{search_type}"
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            return cached_result
        
        results = {}
        
        if search_type in ["hybrid", "graph"]:
            # GraphRAG查询
            try:
                graph_results = await self.graphrag.query_graph(
                    query=query,
                    query_type="global"  # 或根据查询类型智能选择
                )
                results["graph_results"] = graph_results
            except Exception as e:
                self.logger.error(f"GraphRAG query error: {str(e)}")
                results["graph_error"] = str(e)
        
        if search_type in ["hybrid", "vector"]:
            # 向量搜索
            try:
                # 这里需要调用嵌入服务获取查询向量
                query_embedding = await self._get_query_embedding(query)
                vector_results = await self.vector_db.search_similar(
                    collection_name="documents",
                    query_embedding=query_embedding,
                    n_results=10
                )
                results["vector_results"] = vector_results
            except Exception as e:
                self.logger.error(f"Vector search error: {str(e)}")
                results["vector_error"] = str(e)
        
        # 缓存结果
        await self.cache.set(cache_key, results, ttl=3600)  # 1小时缓存
        
        return results
    
    async def get_document_status(self, doc_id: str) -> Dict[str, Any]:
        """获取文档处理状态"""
        return await self.metadata.get_document_metadata(doc_id)
    
    def _generate_doc_id(self) -> str:
        """生成文档ID"""
        import uuid
        return f"doc_{uuid.uuid4().hex[:12]}"
    
    def _extract_text_content(self, parsed_doc: Dict[str, Any]) -> str:
        """从解析文档中提取文本内容"""
        content_parts = []
        
        # 添加标题
        if parsed_doc.get("title"):
            content_parts.append(parsed_doc["title"])
        
        # 添加章节内容
        for section in parsed_doc.get("sections", []):
            if section.get("title"):
                content_parts.append(section["title"])
            content_parts.extend(section.get("content", []))
        
        # 添加表格内容
        for table in parsed_doc.get("tables", []):
            content_parts.append(table.get("content", ""))
        
        return "\n".join(content_parts)
    
    async def _get_query_embedding(self, query: str) -> List[float]:
        """获取查询的嵌入向量"""
        # 这里调用嵌入服务API
        # 可以是OpenAI、Sentence Transformers等
        pass
```

### 2. 查询引擎

```python
# src/core/knowledge/query_engine.py
from typing import Dict, List, Optional, Any
import asyncio

class QueryEngine:
    """轻量化查询引擎"""
    
    def __init__(self, knowledge_manager, cache_manager):
        self.knowledge_manager = knowledge_manager
        self.cache = cache_manager
    
    async def intelligent_search(
        self,
        query: str,
        context: Optional[Dict] = None,
        user_preferences: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """智能搜索 - 自动选择最佳搜索策略"""
        
        # 分析查询类型
        query_analysis = await self._analyze_query(query)
        
        # 根据查询类型选择搜索策略
        if query_analysis["type"] == "factual":
            # 事实性查询，优先使用GraphRAG
            search_type = "graph"
        elif query_analysis["type"] == "semantic":
            # 语义查询，使用向量搜索
            search_type = "vector"
        else:
            # 复合查询，使用混合搜索
            search_type = "hybrid"
        
        # 执行搜索
        results = await self.knowledge_manager.search_knowledge(
            query=query,
            search_type=search_type
        )
        
        # 结果融合和排序
        fused_results = await self._fuse_results(results, query_analysis)
        
        return {
            "query": query,
            "query_type": query_analysis["type"],
            "search_strategy": search_type,
            "results": fused_results,
            "metadata": {
                "total_results": len(fused_results),
                "search_time": query_analysis.get("search_time"),
                "confidence": query_analysis.get("confidence")
            }
        }
    
    async def _analyze_query(self, query: str) -> Dict[str, Any]:
        """分析查询类型和意图"""
        # 简单的查询分析逻辑
        # 在实际应用中可以使用更复杂的NLP分析
        
        query_lower = query.lower()
        
        # 检查是否包含实体关系词汇
        relation_keywords = ["关系", "连接", "相关", "影响", "导致", "关联"]
        if any(keyword in query_lower for keyword in relation_keywords):
            return {"type": "factual", "confidence": 0.8}
        
        # 检查是否是语义搜索
        semantic_keywords = ["类似", "相似", "像", "相关文档"]
        if any(keyword in query_lower for keyword in semantic_keywords):
            return {"type": "semantic", "confidence": 0.7}
        
        # 默认为复合查询
        return {"type": "hybrid", "confidence": 0.6}
    
    async def _fuse_results(
        self,
        results: Dict[str, Any],
        query_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """融合不同来源的搜索结果"""
        
        fused_results = []
        
        # 处理GraphRAG结果
        if "graph_results" in results:
            graph_data = results["graph_results"]
            if "results" in graph_data:
                graph_result = {
                    "source": "graphrag",
                    "type": "answer",
                    "content": graph_data["results"].get("answer", ""),
                    "confidence": 0.9,
                    "supporting_data": graph_data["results"].get("source_communities", [])
                }
                fused_results.append(graph_result)
        
        # 处理向量搜索结果
        if "vector_results" in results:
            vector_data = results["vector_results"]
            for i, (doc, distance, metadata) in enumerate(zip(
                vector_data.get("documents", [[]])[0],
                vector_data.get("distances", [[]])[0],
                vector_data.get("metadatas", [[]])[0]
            )):
                vector_result = {
                    "source": "vector_search",
                    "type": "document",
                    "content": doc,
                    "confidence": 1 - distance,  # 距离越小置信度越高
                    "metadata": metadata,
                    "rank": i + 1
                }
                fused_results.append(vector_result)
        
        # 按置信度排序
        fused_results.sort(key=lambda x: x["confidence"], reverse=True)
        
        return fused_results[:10]  # 返回前10个结果
```

## 缓存策略设计

### 智能缓存管理器

```python
# src/core/knowledge/cache_manager.py
import redis
import json
import hashlib
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta

class CacheManager:
    """智能缓存管理器"""
    
    def __init__(self, redis_config: Dict[str, Any]):
        self.redis_client = redis.Redis(
            host=redis_config.get("host", "localhost"),
            port=redis_config.get("port", 6379),
            db=redis_config.get("db", 0),
            decode_responses=True
        )
        
        # 缓存策略配置
        self.cache_ttl = {
            "document_parsing": 86400 * 7,    # 文档解析结果缓存7天
            "graph_query": 3600,              # 图谱查询结果缓存1小时
            "vector_search": 1800,            # 向量搜索结果缓存30分钟
            "user_session": 86400,            # 用户会话缓存1天
        }
    
    async def get_document_result(self, filename: str, file_content: bytes) -> Optional[Dict]:
        """获取文档解析结果缓存"""
        content_hash = hashlib.md5(file_content).hexdigest()
        cache_key = f"doc_parse:{filename}:{content_hash}"
        
        cached_data = self.redis_client.get(cache_key)
        if cached_data:
            return json.loads(cached_data)
        return None
    
    async def cache_document_result(
        self,
        filename: str,
        file_content: bytes,
        result: Dict[str, Any]
    ):
        """缓存文档解析结果"""
        content_hash = hashlib.md5(file_content).hexdigest()
        cache_key = f"doc_parse:{filename}:{content_hash}"
        
        self.redis_client.setex(
            cache_key,
            self.cache_ttl["document_parsing"],
            json.dumps(result, ensure_ascii=False)
        )
    
    async def get(self, key: str) -> Optional[Any]:
        """通用缓存获取"""
        cached_data = self.redis_client.get(key)
        if cached_data:
            return json.loads(cached_data)
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """通用缓存设置"""
        if ttl:
            self.redis_client.setex(key, ttl, json.dumps(value, ensure_ascii=False))
        else:
            self.redis_client.set(key, json.dumps(value, ensure_ascii=False))
    
    async def invalidate_pattern(self, pattern: str):
        """按模式失效缓存"""
        keys = self.redis_client.keys(pattern)
        if keys:
            self.redis_client.delete(*keys)
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        info = self.redis_client.info()
        return {
            "used_memory": info.get("used_memory_human"),
            "connected_clients": info.get("connected_clients"),
            "keyspace_hits": info.get("keyspace_hits"),
            "keyspace_misses": info.get("keyspace_misses"),
            "hit_rate": info.get("keyspace_hits", 0) / max(
                info.get("keyspace_hits", 0) + info.get("keyspace_misses", 0), 1
            )
        }
```

## 服务编排器

```python
# src/core/knowledge/service_orchestrator.py
from typing import Dict, List, Optional, Any
import asyncio
import logging
from enum import Enum

class ServiceStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"

class ServiceOrchestrator:
    """服务编排器 - 管理外部服务的调用和故障处理"""
    
    def __init__(self, services_config: Dict[str, Any]):
        self.services = {}
        self.service_status = {}
        self.circuit_breakers = {}
        self.logger = logging.getLogger(__name__)
        
        # 初始化服务客户端
        self._initialize_services(services_config)
    
    def _initialize_services(self, config: Dict[str, Any]):
        """初始化外部服务客户端"""
        from .external.unstructured_client import UnstructuredClient
        from .external.graphrag_client import GraphRAGClient
        from .external.vector_db_client import VectorDBClient
        
        # 初始化Unstructured服务
        if "unstructured" in config:
            self.services["unstructured"] = UnstructuredClient(config["unstructured"])
            self.service_status["unstructured"] = ServiceStatus.HEALTHY
        
        # 初始化GraphRAG服务
        if "graphrag" in config:
            self.services["graphrag"] = GraphRAGClient(config["graphrag"])
            self.service_status["graphrag"] = ServiceStatus.HEALTHY
        
        # 初始化向量数据库服务
        if "vector_db" in config:
            self.services["vector_db"] = VectorDBClient(config["vector_db"])
            self.service_status["vector_db"] = ServiceStatus.HEALTHY
    
    async def call_service(
        self,
        service_name: str,
        method_name: str,
        *args,
        **kwargs
    ) -> Any:
        """调用外部服务的方法"""
        
        # 检查服务状态
        if self.service_status.get(service_name) == ServiceStatus.UNHEALTHY:
            raise Exception(f"Service {service_name} is unhealthy")
        
        # 检查熔断器
        if self._is_circuit_open(service_name):
            raise Exception(f"Circuit breaker is open for service {service_name}")
        
        try:
            service = self.services.get(service_name)
            if not service:
                raise Exception(f"Service {service_name} not found")
            
            method = getattr(service, method_name)
            result = await method(*args, **kwargs)
            
            # 调用成功，重置失败计数
            self._record_success(service_name)
            
            return result
            
        except Exception as e:
            # 记录失败
            self._record_failure(service_name)
            self.logger.error(f"Service call failed: {service_name}.{method_name}, error: {str(e)}")
            raise
    
    async def health_check_all_services(self) -> Dict[str, ServiceStatus]:
        """检查所有服务健康状态"""
        health_results = {}
        
        for service_name in self.services:
            try:
                health_status = await self._check_service_health(service_name)
                health_results[service_name] = health_status
                self.service_status[service_name] = health_status
            except Exception as e:
                self.logger.error(f"Health check failed for {service_name}: {str(e)}")
                health_results[service_name] = ServiceStatus.UNHEALTHY
                self.service_status[service_name] = ServiceStatus.UNHEALTHY
        
        return health_results
    
    async def _check_service_health(self, service_name: str) -> ServiceStatus:
        """检查单个服务健康状态"""
        service = self.services.get(service_name)
        
        if service_name == "unstructured":
            # 调用健康检查接口
            try:
                # 这里可以调用服务的健康检查端点
                return ServiceStatus.HEALTHY
            except:
                return ServiceStatus.UNHEALTHY
                
        elif service_name == "graphrag":
            # GraphRAG健康检查
            try:
                return ServiceStatus.HEALTHY
            except:
                return ServiceStatus.UNHEALTHY
                
        elif service_name == "vector_db":
            # 向量数据库健康检查
            try:
                return ServiceStatus.HEALTHY
            except:
                return ServiceStatus.UNHEALTHY
        
        return ServiceStatus.UNHEALTHY
    
    def _is_circuit_open(self, service_name: str) -> bool:
        """检查熔断器是否开启"""
        circuit = self.circuit_breakers.get(service_name, {"failures": 0, "last_failure": None})
        
        # 简单的熔断器逻辑：5次失败后开启熔断器
        return circuit["failures"] >= 5
    
    def _record_success(self, service_name: str):
        """记录服务调用成功"""
        if service_name in self.circuit_breakers:
            self.circuit_breakers[service_name]["failures"] = 0
    
    def _record_failure(self, service_name: str):
        """记录服务调用失败"""
        if service_name not in self.circuit_breakers:
            self.circuit_breakers[service_name] = {"failures": 0, "last_failure": None}
        
        self.circuit_breakers[service_name]["failures"] += 1
        self.circuit_breakers[service_name]["last_failure"] = asyncio.get_event_loop().time()
```

## 系统配置

### 轻量化系统配置

```yaml
# config/lightweight_knowledge_system.yaml
system:
  name: "Lightweight Knowledge Management System"
  version: "1.0.0"
  mode: "lightweight"  # lightweight/full
  
# 外部服务配置
external_services:
  # Unstructured文档解析服务
  unstructured:
    api_url: "http://unstructured-api:8000"
    api_key: "${UNSTRUCTURED_API_KEY}"
    timeout: 300
    max_retries: 3
    
  # Microsoft GraphRAG服务
  graphrag:
    api_url: "http://graphrag-api:8001"
    api_key: "${GRAPHRAG_API_KEY}"
    timeout: 600
    
  # 向量数据库服务
  vector_db:
    type: "chroma"  # chroma/pinecone/weaviate
    host: "chroma-db"
    port: 8000
    
  # LLM服务
  llm_services:
    openai:
      api_key: "${OPENAI_API_KEY}"
      models: ["gpt-4", "gpt-3.5-turbo", "text-embedding-ada-002"]
    anthropic:
      api_key: "${ANTHROPIC_API_KEY}"
      models: ["claude-3-sonnet", "claude-3-haiku"]

# 核心系统配置
core:
  # 缓存配置
  cache:
    redis:
      host: "redis"
      port: 6379
      db: 0
    ttl:
      document_parsing: 604800  # 7天
      graph_query: 3600        # 1小时
      vector_search: 1800      # 30分钟
      
  # 元数据存储
  metadata_store:
    type: "postgresql"
    host: "postgres"
    port: 5432
    database: "knowledge_metadata"
    username: "${POSTGRES_USER}"
    password: "${POSTGRES_PASSWORD}"
    
  # 消息队列
  message_queue:
    type: "redis"
    host: "redis"
    port: 6379
    db: 1

# API配置
api:
  host: "0.0.0.0"
  port: 8080
  cors_enabled: true
  rate_limiting:
    enabled: true
    requests_per_minute: 100
    
# 监控配置
monitoring:
  health_check:
    enabled: true
    interval: 30  # 秒
  metrics:
    enabled: true
    prometheus_endpoint: "/metrics"
  logging:
    level: "INFO"
    format: "json"

# 安全配置
security:
  authentication:
    enabled: true
    type: "jwt"
    secret_key: "${JWT_SECRET_KEY}"
  authorization:
    enabled: true
    default_role: "user"
```

## 部署方案

### Docker Compose部署

```yaml
# docker-compose.yml
version: '3.8'

services:
  # 我们的轻量化知识库系统
  knowledge-system:
    build: .
    ports:
      - "8080:8080"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - UNSTRUCTURED_API_URL=http://unstructured:8000
      - GRAPHRAG_API_URL=http://graphrag:8001
      - CHROMA_HOST=chroma
    depends_on:
      - redis
      - postgres
      - unstructured
      - graphrag
      - chroma
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
      
  # Redis缓存和消息队列
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      
  # PostgreSQL元数据存储
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=knowledge_metadata
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  # Unstructured文档解析服务
  unstructured:
    image: quay.io/unstructured-io/unstructured-api:latest
    ports:
      - "8000:8000"
    environment:
      - UNSTRUCTURED_API_KEY=${UNSTRUCTURED_API_KEY}
    deploy:
      resources:
        limits:
          memory: 4G
          
  # Microsoft GraphRAG服务
  graphrag:
    image: microsoft/graphrag:latest
    ports:
      - "8001:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GRAPHRAG_CONFIG_PATH=/app/config/graphrag.yaml
    volumes:
      - ./config/graphrag.yaml:/app/config/graphrag.yaml
    deploy:
      resources:
        limits:
          memory: 8G
          
  # Chroma向量数据库
  chroma:
    image: chromadb/chroma:latest
    ports:
      - "8002:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000

volumes:
  redis_data:
  postgres_data:
  chroma_data:
```

## 总结

这个轻量化知识库系统设计方案具有以下特点：

### 🎯 **核心优势**

1. **专业分工**：高耗能任务外包给专业服务，我们专注核心业务
2. **轻量高效**：系统保持轻量级，启动快，资源占用少
3. **智能缓存**：多层缓存策略，减少外部服务调用
4. **服务编排**：统一管理外部服务，提供故障处理和熔断机制
5. **易于扩展**：模块化设计，易于添加新的外部服务

### 🔧 **技术特色**

1. **外部服务集成**：Unstructured + GraphRAG + 开源向量数据库
2. **智能查询引擎**：自动选择最佳搜索策略
3. **缓存优化**：针对不同类型数据的差异化缓存策略
4. **故障处理**：熔断器、重试机制、降级策略
5. **监控完善**：服务健康检查、性能监控、日志记录

### 📊 **资源优化**

- **CPU使用**：主要用于API调用和结果处理，CPU占用低
- **内存使用**：主要用于缓存，可控制缓存大小
- **存储需求**：只存储元数据和缓存，存储需求小
- **网络带宽**：主要是API调用，带宽需求适中

这个方案让我们能够以最小的资源投入，获得最大的功能价值，同时保持系统的高性能和可扩展性！

## API接口设计

### RESTful API规范

```python
# src/communication/knowledge/api_gateway.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Optional, Dict, Any
import asyncio

app = FastAPI(
    title="Lightweight Knowledge Management API",
    description="轻量化知识库管理系统API",
    version="1.0.0"
)

# CORS配置
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class KnowledgeAPI:
    """知识库API网关"""
    
    def __init__(self, knowledge_manager, query_engine, service_orchestrator):
        self.knowledge_manager = knowledge_manager
        self.query_engine = query_engine
        self.service_orchestrator = service_orchestrator

# 文档管理API
@app.post("/api/v1/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    user_id: str = "default"
):
    """上传并处理文档"""
    try:
        file_content = await file.read()
        result = await knowledge_manager.process_document(
            file_content=file_content,
            filename=file.filename,
            user_id=user_id
        )
        return {
            "success": True,
            "data": result,
            "message": "Document uploaded and processing started"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/documents/{doc_id}/status")
async def get_document_status(doc_id: str):
    """获取文档处理状态"""
    try:
        status = await knowledge_manager.get_document_status(doc_id)
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        raise HTTPException(status_code=404, detail="Document not found")

@app.post("/api/v1/documents/batch_upload")
async def batch_upload_documents(
    files: List[UploadFile] = File(...),
    user_id: str = "default"
):
    """批量上传文档"""
    results = []
    
    for file in files:
        try:
            file_content = await file.read()
            result = await knowledge_manager.process_document(
                file_content=file_content,
                filename=file.filename,
                user_id=user_id
            )
            results.append({
                "filename": file.filename,
                "success": True,
                "doc_id": result["doc_id"]
            })
        except Exception as e:
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
    
    return {
        "success": True,
        "data": {
            "total_files": len(files),
            "successful": len([r for r in results if r["success"]]),
            "failed": len([r for r in results if not r["success"]]),
            "results": results
        }
    }

# 知识搜索API
@app.post("/api/v1/search")
async def search_knowledge(
    query: str,
    search_type: str = "hybrid",  # hybrid/graph/vector
    max_results: int = 10,
    user_id: str = "default"
):
    """智能知识搜索"""
    try:
        results = await query_engine.intelligent_search(
            query=query,
            context={"search_type": search_type, "max_results": max_results}
        )
        return {
            "success": True,
            "data": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/search/graph")
async def graph_search(
    query: str,
    query_type: str = "global",  # global/local
    max_tokens: int = 4000
):
    """GraphRAG专用搜索"""
    try:
        result = await service_orchestrator.call_service(
            "graphrag",
            "query_graph",
            query=query,
            query_type=query_type,
            config={"max_tokens": max_tokens}
        )
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/search/vector")
async def vector_search(
    query: str,
    collection_name: str = "documents",
    n_results: int = 10
):
    """向量相似性搜索"""
    try:
        # 获取查询向量
        query_embedding = await get_query_embedding(query)
        
        result = await service_orchestrator.call_service(
            "vector_db",
            "search_similar",
            collection_name=collection_name,
            query_embedding=query_embedding,
            n_results=n_results
        )
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# 系统管理API
@app.get("/api/v1/system/health")
async def system_health():
    """系统健康检查"""
    try:
        health_status = await service_orchestrator.health_check_all_services()
        cache_stats = await cache_manager.get_cache_stats()
        
        return {
            "success": True,
            "data": {
                "services": health_status,
                "cache": cache_stats,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/system/stats")
async def system_statistics():
    """系统统计信息"""
    try:
        # 获取各种统计信息
        stats = {
            "documents": {
                "total": await metadata_store.count_documents(),
                "processed": await metadata_store.count_processed_documents(),
                "processing": await metadata_store.count_processing_documents()
            },
            "cache": await cache_manager.get_cache_stats(),
            "services": await service_orchestrator.health_check_all_services()
        }
        
        return {
            "success": True,
            "data": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# WebSocket支持实时通知
@app.websocket("/ws/notifications")
async def websocket_notifications(websocket: WebSocket):
    """WebSocket实时通知"""
    await websocket.accept()
    
    try:
        while True:
            # 发送系统状态更新
            status_update = await get_system_status_update()
            await websocket.send_json(status_update)
            await asyncio.sleep(5)  # 每5秒发送一次更新
            
    except Exception as e:
        await websocket.close()
```

## 用户界面设计

### Web Dashboard界面

```typescript
// frontend/src/components/KnowledgeManager.tsx
import React, { useState, useEffect } from 'react';
import { Upload, Search, FileText, BarChart3, Settings } from 'lucide-react';

interface Document {
  doc_id: string;
  filename: string;
  status: 'parsing' | 'processing' | 'completed' | 'error';
  created_at: string;
  progress?: number;
}

interface SearchResult {
  source: string;
  type: string;
  content: string;
  confidence: number;
  metadata?: any;
}

const KnowledgeManager: React.FC = () => {
  const [documents, setDocuments] = useState<Document[]>([]);
  const [searchQuery, setSearchQuery] = useState('');
  const [searchResults, setSearchResults] = useState<SearchResult[]>([]);
  const [systemStats, setSystemStats] = useState<any>({});
  const [isUploading, setIsUploading] = useState(false);

  // 文档上传组件
  const DocumentUpload = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <Upload className="mr-2" />
        文档上传
      </h2>
      
      <div className="border-2 border-dashed border-gray-300 rounded-lg p-8 text-center">
        <input
          type="file"
          multiple
          accept=".pdf,.docx,.xlsx,.pptx,.txt,.md"
          onChange={handleFileUpload}
          className="hidden"
          id="file-upload"
        />
        <label
          htmlFor="file-upload"
          className="cursor-pointer flex flex-col items-center"
        >
          <FileText className="w-12 h-12 text-gray-400 mb-4" />
          <p className="text-lg font-medium">点击上传文档</p>
          <p className="text-sm text-gray-500">
            支持 PDF, Word, Excel, PowerPoint, 文本文件
          </p>
        </label>
      </div>
      
      {isUploading && (
        <div className="mt-4">
          <div className="bg-blue-100 border border-blue-400 text-blue-700 px-4 py-3 rounded">
            正在上传和处理文档...
          </div>
        </div>
      )}
    </div>
  );

  // 智能搜索组件
  const IntelligentSearch = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <Search className="mr-2" />
        智能搜索
      </h2>
      
      <div className="flex space-x-4 mb-4">
        <input
          type="text"
          value={searchQuery}
          onChange={(e) => setSearchQuery(e.target.value)}
          placeholder="输入搜索问题..."
          className="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500"
          onKeyPress={(e) => e.key === 'Enter' && handleSearch()}
        />
        <button
          onClick={handleSearch}
          className="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700"
        >
          搜索
        </button>
      </div>
      
      <div className="flex space-x-2 mb-4">
        <button className="px-3 py-1 bg-gray-200 rounded-full text-sm">
          混合搜索
        </button>
        <button className="px-3 py-1 bg-gray-200 rounded-full text-sm">
          图谱搜索
        </button>
        <button className="px-3 py-1 bg-gray-200 rounded-full text-sm">
          向量搜索
        </button>
      </div>
      
      {searchResults.length > 0 && (
        <div className="space-y-4">
          {searchResults.map((result, index) => (
            <div key={index} className="border border-gray-200 rounded-lg p-4">
              <div className="flex justify-between items-start mb-2">
                <span className="px-2 py-1 bg-blue-100 text-blue-800 rounded text-xs">
                  {result.source}
                </span>
                <span className="text-sm text-gray-500">
                  置信度: {(result.confidence * 100).toFixed(1)}%
                </span>
              </div>
              <p className="text-gray-800">{result.content}</p>
            </div>
          ))}
        </div>
      )}
    </div>
  );

  // 文档状态监控
  const DocumentStatus = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <FileText className="mr-2" />
        文档状态
      </h2>
      
      <div className="space-y-3">
        {documents.map((doc) => (
          <div key={doc.doc_id} className="flex justify-between items-center p-3 border border-gray-200 rounded">
            <div>
              <p className="font-medium">{doc.filename}</p>
              <p className="text-sm text-gray-500">{doc.created_at}</p>
            </div>
            <div className="text-right">
              <StatusBadge status={doc.status} />
              {doc.progress && (
                <div className="w-24 bg-gray-200 rounded-full h-2 mt-1">
                  <div
                    className="bg-blue-600 h-2 rounded-full"
                    style={{ width: `${doc.progress}%` }}
                  ></div>
                </div>
              )}
            </div>
          </div>
        ))}
      </div>
    </div>
  );

  // 系统监控面板
  const SystemDashboard = () => (
    <div className="bg-white rounded-lg shadow p-6">
      <h2 className="text-xl font-bold mb-4 flex items-center">
        <BarChart3 className="mr-2" />
        系统监控
      </h2>
      
      <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
        <div className="text-center">
          <p className="text-2xl font-bold text-blue-600">
            {systemStats.documents?.total || 0}
          </p>
          <p className="text-sm text-gray-500">总文档数</p>
        </div>
        <div className="text-center">
          <p className="text-2xl font-bold text-green-600">
            {systemStats.documents?.processed || 0}
          </p>
          <p className="text-sm text-gray-500">已处理</p>
        </div>
        <div className="text-center">
          <p className="text-2xl font-bold text-yellow-600">
            {systemStats.documents?.processing || 0}
          </p>
          <p className="text-sm text-gray-500">处理中</p>
        </div>
        <div className="text-center">
          <p className="text-2xl font-bold text-purple-600">
            {((systemStats.cache?.hit_rate || 0) * 100).toFixed(1)}%
          </p>
          <p className="text-sm text-gray-500">缓存命中率</p>
        </div>
      </div>
      
      <div className="mt-6">
        <h3 className="font-medium mb-2">外部服务状态</h3>
        <div className="space-y-2">
          {Object.entries(systemStats.services || {}).map(([service, status]) => (
            <div key={service} className="flex justify-between items-center">
              <span className="capitalize">{service}</span>
              <ServiceStatusBadge status={status as string} />
            </div>
          ))}
        </div>
      </div>
    </div>
  );

  // 事件处理函数
  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files) return;

    setIsUploading(true);
    
    const formData = new FormData();
    Array.from(files).forEach(file => formData.append('files', file));
    
    try {
      const response = await fetch('/api/v1/documents/batch_upload', {
        method: 'POST',
        body: formData,
      });
      
      const result = await response.json();
      if (result.success) {
        // 刷新文档列表
        fetchDocuments();
      }
    } catch (error) {
      console.error('Upload failed:', error);
    } finally {
      setIsUploading(false);
    }
  };

  const handleSearch = async () => {
    if (!searchQuery.trim()) return;
    
    try {
      const response = await fetch('/api/v1/search', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: searchQuery }),
      });
      
      const result = await response.json();
      if (result.success) {
        setSearchResults(result.data.results);
      }
    } catch (error) {
      console.error('Search failed:', error);
    }
  };

  const fetchDocuments = async () => {
    // 获取文档列表的逻辑
  };

  const fetchSystemStats = async () => {
    try {
      const response = await fetch('/api/v1/system/stats');
      const result = await response.json();
      if (result.success) {
        setSystemStats(result.data);
      }
    } catch (error) {
      console.error('Failed to fetch system stats:', error);
    }
  };

  useEffect(() => {
    fetchDocuments();
    fetchSystemStats();
    
    // 设置定时刷新
    const interval = setInterval(fetchSystemStats, 30000); // 30秒刷新一次
    return () => clearInterval(interval);
  }, []);

  return (
    <div className="min-h-screen bg-gray-100">
      <header className="bg-white shadow">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="flex justify-between items-center py-6">
            <h1 className="text-3xl font-bold text-gray-900">
              轻量化知识库管理系统
            </h1>
            <Settings className="w-6 h-6 text-gray-500 cursor-pointer" />
          </div>
        </div>
      </header>
      
      <main className="max-w-7xl mx-auto py-6 px-4 sm:px-6 lg:px-8">
        <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
          <DocumentUpload />
          <IntelligentSearch />
          <DocumentStatus />
          <SystemDashboard />
        </div>
      </main>
    </div>
  );
};

// 辅助组件
const StatusBadge: React.FC<{ status: string }> = ({ status }) => {
  const colors = {
    parsing: 'bg-yellow-100 text-yellow-800',
    processing: 'bg-blue-100 text-blue-800',
    completed: 'bg-green-100 text-green-800',
    error: 'bg-red-100 text-red-800',
  };
  
  return (
    <span className={`px-2 py-1 rounded-full text-xs ${colors[status as keyof typeof colors]}`}>
      {status}
    </span>
  );
};

const ServiceStatusBadge: React.FC<{ status: string }> = ({ status }) => {
  const colors = {
    healthy: 'bg-green-100 text-green-800',
    degraded: 'bg-yellow-100 text-yellow-800',
    unhealthy: 'bg-red-100 text-red-800',
  };
  
  return (
    <span className={`px-2 py-1 rounded-full text-xs ${colors[status as keyof typeof colors]}`}>
      {status}
    </span>
  );
};

export default KnowledgeManager;
```

## 实施计划

### 第一阶段：基础架构搭建（2周）

#### Week 1: 核心框架搭建
```bash
Day 1-2: 项目初始化
- 创建项目结构
- 配置开发环境
- 设置基础依赖

Day 3-4: 外部服务客户端开发
- UnstructuredClient实现
- GraphRAGClient实现
- VectorDBClient实现

Day 5-7: 核心业务层开发
- KnowledgeManager基础功能
- ServiceOrchestrator实现
- CacheManager实现
```

#### Week 2: API和存储层
```bash
Day 8-10: API网关开发
- FastAPI应用搭建
- 基础API接口实现
- 错误处理和验证

Day 11-12: 数据存储层
- PostgreSQL元数据存储
- Redis缓存配置
- 数据模型设计

Day 13-14: 集成测试
- 服务集成测试
- API接口测试
- 性能基准测试
```

### 第二阶段：功能完善（2周）

#### Week 3: 高级功能开发
```bash
Day 15-17: 查询引擎优化
- 智能查询分析
- 结果融合算法
- 搜索策略优化

Day 18-19: 缓存策略优化
- 多级缓存实现
- 缓存失效策略
- 性能监控

Day 20-21: 监控和健康检查
- 服务健康检查
- 性能指标收集
- 告警机制
```

#### Week 4: 用户界面开发
```bash
Day 22-24: 前端界面开发
- React组件实现
- 实时状态更新
- 用户交互优化

Day 25-26: 系统集成
- 前后端集成
- WebSocket实时通信
- 完整流程测试

Day 27-28: 部署和优化
- Docker容器化
- 部署脚本编写
- 性能调优
```

### 第三阶段：测试和部署（1周）

#### Week 5: 测试和上线
```bash
Day 29-30: 压力测试
- 并发性能测试
- 大文件处理测试
- 系统稳定性测试

Day 31-32: 安全测试
- API安全测试
- 数据安全验证
- 权限控制测试

Day 33-35: 部署上线
- 生产环境部署
- 监控配置
- 文档完善
```

## 成本效益分析

### 资源需求对比

| 组件 | 传统方案 | 轻量化方案 | 节省比例 |
|------|----------|------------|----------|
| CPU核心 | 16-32核 | 4-8核 | 50-75% |
| 内存 | 32-64GB | 8-16GB | 50-75% |
| 存储 | 1-5TB | 100-500GB | 80-90% |
| GPU | 需要 | 不需要 | 100% |

### 开发成本对比

| 项目 | 传统方案 | 轻量化方案 | 节省 |
|------|----------|------------|------|
| 开发时间 | 6-12个月 | 1-2个月 | 70-80% |
| 团队规模 | 8-12人 | 3-5人 | 50-60% |
| 技术复杂度 | 高 | 中 | - |
| 维护成本 | 高 | 低 | 60-70% |

### 运营优势

1. **快速上线**：1-2个月即可投入使用
2. **低维护成本**：专业服务由供应商维护
3. **弹性扩展**：根据需求调整外部服务规模
4. **技术更新**：自动获得外部服务的技术升级
5. **风险分散**：降低技术风险和维护负担

这个轻量化方案让我们能够以最小的投入，快速构建一个功能完整、性能优良的知识库管理系统！ 