# é€šä¿¡åŸŸä¸ååŒåŸŸå¤–éƒ¨æœåŠ¡ç»Ÿä¸€è°ƒåº¦æ–¹æ¡ˆ

## æ–¹æ¡ˆæ¦‚è¿°

æœ¬æ–¹æ¡ˆè®¾è®¡äº†é€šä¿¡åŸŸ(Communication)å’ŒååŒåŸŸ(Coordination)åä½œç®¡ç†å¤–éƒ¨æœåŠ¡çš„ç»Ÿä¸€è°ƒåº¦æ¶æ„ï¼Œå®ç°å¤§æ¨¡å‹APIã€æ–‡æ¡£è§£ææœåŠ¡ã€çŸ¥è¯†åº“æœåŠ¡ç­‰å¤–éƒ¨èµ„æºçš„æ™ºèƒ½è°ƒåº¦ã€è´Ÿè½½å‡è¡¡å’Œæ•…éšœå¤„ç†ã€‚

## æ•´ä½“æ¶æ„è®¾è®¡

### åŒåŸŸåä½œæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Application Layer åº”ç”¨å±‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Knowledge       â”‚  â”‚ Query Engine    â”‚  â”‚ Workflow        â”‚  â”‚ Chat Interface  â”‚ â”‚
â”‚  â”‚ Manager         â”‚  â”‚                 â”‚  â”‚ Engine          â”‚  â”‚                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Communication Domain é€šä¿¡åŸŸ                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ External        â”‚  â”‚ BIR Router      â”‚  â”‚ Protocol        â”‚  â”‚ Message         â”‚ â”‚
â”‚  â”‚ Service Gateway â”‚  â”‚ (Enhanced)      â”‚  â”‚ Adapters        â”‚  â”‚ Dispatcher      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Service         â”‚  â”‚ Load Balancer   â”‚  â”‚ Circuit         â”‚  â”‚ Cache           â”‚ â”‚
â”‚  â”‚ Discovery       â”‚  â”‚                 â”‚  â”‚ Breaker         â”‚  â”‚ Manager         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Coordination Domain ååŒåŸŸ                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Service         â”‚  â”‚ Resource        â”‚  â”‚ Task            â”‚  â”‚ Health          â”‚ â”‚
â”‚  â”‚ Registry        â”‚  â”‚ Allocator       â”‚  â”‚ Scheduler       â”‚  â”‚ Monitor         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Container       â”‚  â”‚ Policy          â”‚  â”‚ Metrics         â”‚  â”‚ Governance      â”‚ â”‚
â”‚  â”‚ Manager         â”‚  â”‚ Engine          â”‚  â”‚ Collector       â”‚  â”‚ Controller      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          External Services å¤–éƒ¨æœåŠ¡å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LLM Services    â”‚  â”‚ Document        â”‚  â”‚ Knowledge       â”‚  â”‚ Vector          â”‚ â”‚
â”‚  â”‚ OpenAI/Claude   â”‚  â”‚ Processing      â”‚  â”‚ Graph           â”‚  â”‚ Database        â”‚ â”‚
â”‚  â”‚ /Local Models   â”‚  â”‚ Unstructured    â”‚  â”‚ GraphRAG        â”‚  â”‚ Chroma/Pinecone â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 1. åŒåŸŸèŒè´£åˆ†å·¥

#### é€šä¿¡åŸŸèŒè´£
- **å¤–éƒ¨æœåŠ¡ç½‘å…³**ï¼šç»Ÿä¸€çš„å¤–éƒ¨æœåŠ¡è®¿é—®å…¥å£
- **æ™ºèƒ½è·¯ç”±**ï¼šåŸºäºBIRè·¯ç”±å™¨çš„å¤–éƒ¨æœåŠ¡è·¯ç”±
- **åè®®é€‚é…**ï¼šä¸åŒå¤–éƒ¨æœåŠ¡çš„åè®®è½¬æ¢å’Œé€‚é…
- **æ¶ˆæ¯è°ƒåº¦**ï¼šå¤–éƒ¨æœåŠ¡è¯·æ±‚çš„æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†
- **ç¼“å­˜ç®¡ç†**ï¼šå¤–éƒ¨æœåŠ¡å“åº”çš„æ™ºèƒ½ç¼“å­˜

#### ååŒåŸŸèŒè´£
- **æœåŠ¡æ³¨å†Œ**ï¼šå¤–éƒ¨æœåŠ¡çš„æ³¨å†Œã€å‘ç°å’ŒçŠ¶æ€ç®¡ç†
- **èµ„æºè°ƒåº¦**ï¼šå¤–éƒ¨æœåŠ¡èµ„æºçš„åˆ†é…å’Œä¼˜åŒ–
- **ä»»åŠ¡ç¼–æ’**ï¼šå¤æ‚å¤–éƒ¨æœåŠ¡è°ƒç”¨çš„ä»»åŠ¡ç¼–æ’
- **å¥åº·ç›‘æ§**ï¼šå¤–éƒ¨æœåŠ¡çš„å¥åº·æ£€æŸ¥å’Œæ•…éšœå¤„ç†
- **æ²»ç†æ§åˆ¶**ï¼šå¤–éƒ¨æœåŠ¡çš„æƒé™ã€é…é¢å’Œç­–ç•¥ç®¡ç†

### 2. ç»Ÿä¸€è°ƒåº¦ç­–ç•¥

```python
# å¤–éƒ¨æœåŠ¡è°ƒåº¦ç­–ç•¥æšä¸¾
class ExternalServiceSchedulingStrategy(Enum):
    """å¤–éƒ¨æœåŠ¡è°ƒåº¦ç­–ç•¥"""
    ROUND_ROBIN = "round_robin"           # è½®è¯¢è°ƒåº¦
    LEAST_LOADED = "least_loaded"         # æœ€å°‘è´Ÿè½½
    WEIGHTED_ROUND_ROBIN = "weighted"     # åŠ æƒè½®è¯¢
    PRIORITY_BASED = "priority"           # ä¼˜å…ˆçº§è°ƒåº¦
    COST_OPTIMIZED = "cost_optimized"     # æˆæœ¬ä¼˜åŒ–
    LATENCY_OPTIMIZED = "latency"         # å»¶è¿Ÿä¼˜åŒ–
    INTELLIGENT = "intelligent"           # æ™ºèƒ½è°ƒåº¦
```

## æ ¸å¿ƒç»„ä»¶å®ç°

### 1. å¢å¼ºçš„BIRè·¯ç”±å™¨ (é€šä¿¡åŸŸ)

```python
# src/communication/dispatcher/enhanced_bir_router.py
from typing import Dict, List, Optional, Any
from enum import Enum
import asyncio
import logging
from dataclasses import dataclass

class ServiceCategory(Enum):
    """æœåŠ¡ç±»åˆ«"""
    LLM_SERVICE = "llm"
    DOCUMENT_PROCESSING = "document"
    KNOWLEDGE_GRAPH = "knowledge_graph"
    VECTOR_DATABASE = "vector_db"
    EMBEDDING_SERVICE = "embedding"

@dataclass
class ExternalServiceRequest:
    """å¤–éƒ¨æœåŠ¡è¯·æ±‚"""
    request_id: str
    service_category: ServiceCategory
    service_name: str
    method: str
    data: Dict[str, Any]
    priority: int = 5
    timeout: int = 30
    retry_count: int = 0
    max_retries: int = 3
    user_id: Optional[str] = None
    session_id: Optional[str] = None

class EnhancedBIRRouter:
    """å¢å¼ºçš„BIRè·¯ç”±å™¨ - æ”¯æŒå¤–éƒ¨æœåŠ¡è·¯ç”±"""
    
    def __init__(self):
        self.service_gateway = None  # å¤–éƒ¨æœåŠ¡ç½‘å…³
        self.coordination_client = None  # ååŒåŸŸå®¢æˆ·ç«¯
        self.load_balancer = LoadBalancer()
        self.circuit_breaker = CircuitBreakerManager()
        self.cache_manager = CacheManager()
        self.metrics_collector = MetricsCollector()
        self.logger = logging.getLogger(__name__)
    
    async def initialize(self, service_gateway, coordination_client):
        """åˆå§‹åŒ–è·¯ç”±å™¨"""
        self.service_gateway = service_gateway
        self.coordination_client = coordination_client
        await self.load_balancer.initialize()
        self.logger.info("Enhanced BIR Router initialized")
    
    async def route_external_service_request(
        self,
        request: ExternalServiceRequest
    ) -> Dict[str, Any]:
        """è·¯ç”±å¤–éƒ¨æœåŠ¡è¯·æ±‚"""
        
        try:
            # 1. æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(request)
            cached_response = await self.cache_manager.get(cache_key)
            if cached_response:
                self.metrics_collector.record_cache_hit(request.service_category.value)
                return cached_response
            
            # 2. ä»ååŒåŸŸè·å–å¯ç”¨æœåŠ¡å®ä¾‹
            available_services = await self.coordination_client.discover_services(
                service_category=request.service_category,
                service_name=request.service_name
            )
            
            if not available_services:
                raise Exception(f"No available services for {request.service_name}")
            
            # 3. è´Ÿè½½å‡è¡¡é€‰æ‹©æœåŠ¡å®ä¾‹
            selected_service = await self.load_balancer.select_service(
                available_services,
                strategy=self._get_scheduling_strategy(request)
            )
            
            # 4. æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
            if self.circuit_breaker.is_open(selected_service.service_id):
                # å°è¯•æ•…éšœè½¬ç§»
                selected_service = await self._handle_failover(
                    available_services, 
                    selected_service
                )
            
            # 5. æ‰§è¡Œå¤–éƒ¨æœåŠ¡è°ƒç”¨
            response = await self.service_gateway.call_service(
                service_id=selected_service.service_id,
                method=request.method,
                data=request.data,
                timeout=request.timeout
            )
            
            # 6. å¤„ç†å“åº”
            if response.success:
                # ç¼“å­˜æˆåŠŸå“åº”
                await self.cache_manager.set(cache_key, response.data)
                self.circuit_breaker.record_success(selected_service.service_id)
                
                # æ›´æ–°è´Ÿè½½ä¿¡æ¯
                await self.load_balancer.update_service_load(
                    selected_service.service_id,
                    response.response_time
                )
            else:
                self.circuit_breaker.record_failure(selected_service.service_id)
                
                # é‡è¯•é€»è¾‘
                if request.retry_count < request.max_retries:
                    request.retry_count += 1
                    return await self.route_external_service_request(request)
            
            # 7. è®°å½•æŒ‡æ ‡
            self.metrics_collector.record_request(
                request.service_category.value,
                response
            )
            
            return response.data
            
        except Exception as e:
            self.logger.error(f"External service routing failed: {str(e)}")
            
            # å°è¯•é™çº§æœåŠ¡
            fallback_response = await self._handle_fallback(request, str(e))
            if fallback_response:
                return fallback_response
            
            raise
    
    def _get_scheduling_strategy(self, request: ExternalServiceRequest) -> str:
        """æ ¹æ®è¯·æ±‚ç±»å‹è·å–è°ƒåº¦ç­–ç•¥"""
        
        # LLMæœåŠ¡ä¼˜å…ˆè€ƒè™‘æˆæœ¬å’Œå»¶è¿Ÿ
        if request.service_category == ServiceCategory.LLM_SERVICE:
            if request.priority > 7:  # é«˜ä¼˜å…ˆçº§
                return "latency_optimized"
            else:
                return "cost_optimized"
        
        # æ–‡æ¡£å¤„ç†æœåŠ¡è€ƒè™‘è´Ÿè½½å‡è¡¡
        elif request.service_category == ServiceCategory.DOCUMENT_PROCESSING:
            return "least_loaded"
        
        # çŸ¥è¯†å›¾è°±æœåŠ¡è€ƒè™‘èµ„æºå¯†é›†å‹
        elif request.service_category == ServiceCategory.KNOWLEDGE_GRAPH:
            return "weighted_round_robin"
        
        # é»˜è®¤æ™ºèƒ½è°ƒåº¦
        return "intelligent"
    
    async def _handle_failover(
        self,
        available_services: List,
        failed_service
    ):
        """å¤„ç†æ•…éšœè½¬ç§»"""
        
        # ä»å¯ç”¨æœåŠ¡ä¸­æ’é™¤å¤±è´¥çš„æœåŠ¡
        healthy_services = [
            s for s in available_services 
            if s.service_id != failed_service.service_id
        ]
        
        if not healthy_services:
            raise Exception("No healthy services available for failover")
        
        # é€‰æ‹©æœ€ä½³æ›¿ä»£æœåŠ¡
        return await self.load_balancer.select_service(
            healthy_services,
            strategy="least_loaded"
        )
    
    async def _handle_fallback(
        self,
        request: ExternalServiceRequest,
        error_message: str
    ) -> Optional[Dict[str, Any]]:
        """å¤„ç†é™çº§æœåŠ¡"""
        
        # LLMæœåŠ¡é™çº§ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–ç¼“å­˜å“åº”
        if request.service_category == ServiceCategory.LLM_SERVICE:
            return await self._llm_fallback(request)
        
        # æ–‡æ¡£å¤„ç†é™çº§ï¼šä½¿ç”¨ç®€åŒ–å¤„ç†
        elif request.service_category == ServiceCategory.DOCUMENT_PROCESSING:
            return await self._document_processing_fallback(request)
        
        # å…¶ä»–æœåŠ¡æš‚æ—¶è¿”å›é”™è¯¯
        return {
            "error": f"Service temporarily unavailable: {error_message}",
            "fallback": True
        }
    
    async def _llm_fallback(self, request: ExternalServiceRequest) -> Dict[str, Any]:
        """LLMæœåŠ¡é™çº§å¤„ç†"""
        
        # å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        try:
            local_llm_response = await self.coordination_client.call_local_llm(
                request.data
            )
            return {
                "response": local_llm_response,
                "fallback": True,
                "source": "local_model"
            }
        except:
            # è¿”å›é¢„è®¾å“åº”
            return {
                "response": "Service temporarily unavailable. Please try again later.",
                "fallback": True,
                "source": "preset_response"
            }
    
    async def _document_processing_fallback(
        self,
        request: ExternalServiceRequest
    ) -> Dict[str, Any]:
        """æ–‡æ¡£å¤„ç†æœåŠ¡é™çº§"""
        
        # ä½¿ç”¨ç®€åŒ–çš„æ–‡æ¡£å¤„ç†
        return {
            "processed": False,
            "message": "Document processing service unavailable, queued for later processing",
            "fallback": True,
            "queue_id": f"queue_{request.request_id}"
        }
    
    def _generate_cache_key(self, request: ExternalServiceRequest) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        key_data = f"{request.service_category.value}:{request.service_name}:{request.method}:{str(request.data)}"
        return hashlib.md5(key_data.encode()).hexdigest()
```

### 2. å¤–éƒ¨æœåŠ¡åè°ƒå™¨ (ååŒåŸŸ)

```python
# src/coordination/external/external_service_coordinator.py
from typing import Dict, List, Optional, Any
import asyncio
import logging
from datetime import datetime, timedelta

class ExternalServiceCoordinator:
    """å¤–éƒ¨æœåŠ¡åè°ƒå™¨ - ååŒåŸŸå¤–éƒ¨æœåŠ¡ç®¡ç†"""
    
    def __init__(self):
        self.service_registry = None  # æœåŠ¡æ³¨å†Œä¸­å¿ƒ
        self.task_scheduler = None    # ä»»åŠ¡è°ƒåº¦å™¨
        self.resource_allocator = None # èµ„æºåˆ†é…å™¨
        self.health_monitor = None    # å¥åº·ç›‘æ§å™¨
        self.policy_engine = PolicyEngine()
        self.metrics_collector = MetricsCollector()
        self.logger = logging.getLogger(__name__)
    
    async def initialize(self, registry, scheduler, allocator, monitor):
        """åˆå§‹åŒ–åè°ƒå™¨"""
        self.service_registry = registry
        self.task_scheduler = scheduler
        self.resource_allocator = allocator
        self.health_monitor = monitor
        await self.policy_engine.initialize()
        self.logger.info("External Service Coordinator initialized")
    
    async def discover_services(
        self,
        service_category: ServiceCategory,
        service_name: str,
        requirements: Optional[Dict] = None
    ) -> List[Dict[str, Any]]:
        """å‘ç°å¯ç”¨çš„å¤–éƒ¨æœåŠ¡"""
        
        # 1. ä»æœåŠ¡æ³¨å†Œä¸­å¿ƒè·å–æœåŠ¡åˆ—è¡¨
        registered_services = await self.service_registry.find_services(
            service_name=service_name,
            service_type=service_category.value
        )
        
        # 2. è¿‡æ»¤å¥åº·çš„æœåŠ¡
        healthy_services = []
        for service in registered_services:
            health_status = await self.health_monitor.get_service_health(
                service.service_id
            )
            if health_status.is_healthy:
                healthy_services.append(service)
        
        # 3. åº”ç”¨ç­–ç•¥è¿‡æ»¤
        filtered_services = await self.policy_engine.apply_service_policies(
            healthy_services,
            requirements or {}
        )
        
        # 4. æ·»åŠ è´Ÿè½½å’Œæ€§èƒ½ä¿¡æ¯
        enriched_services = []
        for service in filtered_services:
            metrics = self.metrics_collector.get_service_metrics(service.service_id)
            service_info = {
                "service_id": service.service_id,
                "service_name": service.service_name,
                "endpoint": service.endpoint,
                "load": metrics.get("current_load", 0.0),
                "avg_response_time": metrics.get("avg_response_time", 0.0),
                "success_rate": metrics.get("success_rate", 1.0),
                "cost_per_request": metrics.get("cost_per_request", 0.0),
                "capabilities": service.metadata.get("capabilities", [])
            }
            enriched_services.append(service_info)
        
        return enriched_services
    
    async def schedule_external_service_task(
        self,
        task_definition: Dict[str, Any]
    ) -> str:
        """è°ƒåº¦å¤–éƒ¨æœåŠ¡ä»»åŠ¡"""
        
        # 1. åˆ›å»ºä»»åŠ¡
        task_id = await self.task_scheduler.submit_task(
            task_name=f"external_service_{task_definition['service_name']}",
            task_type="external_service",
            priority=task_definition.get("priority", 5),
            timeout=task_definition.get("timeout", 300),
            data=task_definition
        )
        
        # 2. åˆ†é…èµ„æº
        resource_requirements = self._calculate_resource_requirements(
            task_definition
        )
        
        success = await self.resource_allocator.allocate_resources(
            request_id=task_id,
            resources=resource_requirements,
            priority=task_definition.get("priority", 5)
        )
        
        if not success:
            await self.task_scheduler.fail_task(
                task_id, 
                "Resource allocation failed"
            )
            raise Exception("Failed to allocate resources for external service task")
        
        return task_id
    
    async def monitor_external_services(self):
        """ç›‘æ§å¤–éƒ¨æœåŠ¡çŠ¶æ€"""
        
        while True:
            try:
                # è·å–æ‰€æœ‰æ³¨å†Œçš„å¤–éƒ¨æœåŠ¡
                all_services = await self.service_registry.get_all_services()
                
                for service in all_services:
                    # å¥åº·æ£€æŸ¥
                    health_status = await self.health_monitor.check_service_health(
                        service.service_id
                    )
                    
                    # æ›´æ–°æœåŠ¡çŠ¶æ€
                    await self.service_registry.update_service_status(
                        service.service_id,
                        health_status
                    )
                    
                    # æ”¶é›†æŒ‡æ ‡
                    metrics = await self._collect_service_metrics(service)
                    self.metrics_collector.update_service_metrics(
                        service.service_id,
                        metrics
                    )
                
                # æ‰§è¡Œè‡ªåŠ¨ä¼˜åŒ–
                await self._optimize_service_allocation()
                
            except Exception as e:
                self.logger.error(f"External service monitoring error: {str(e)}")
            
            # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            await asyncio.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    async def _collect_service_metrics(self, service) -> Dict[str, Any]:
        """æ”¶é›†æœåŠ¡æŒ‡æ ‡"""
        
        # è¿™é‡Œå¯ä»¥è°ƒç”¨å…·ä½“çš„æŒ‡æ ‡æ”¶é›†é€»è¾‘
        # ä¾‹å¦‚ï¼šå“åº”æ—¶é—´ã€æˆåŠŸç‡ã€ååé‡ç­‰
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "current_load": 0.5,  # ç¤ºä¾‹å€¼
            "avg_response_time": 150.0,  # æ¯«ç§’
            "success_rate": 0.99,
            "requests_per_minute": 100,
            "cost_per_request": 0.001  # ç¾å…ƒ
        }
    
    async def _optimize_service_allocation(self):
        """ä¼˜åŒ–æœåŠ¡åˆ†é…"""
        
        # 1. åˆ†æå½“å‰è´Ÿè½½åˆ†å¸ƒ
        load_distribution = await self._analyze_load_distribution()
        
        # 2. è¯†åˆ«è¿‡è½½æœåŠ¡
        overloaded_services = [
            service_id for service_id, load in load_distribution.items()
            if load > 0.8  # 80%ä»¥ä¸Šè®¤ä¸ºè¿‡è½½
        ]
        
        # 3. æ‰§è¡Œè´Ÿè½½é‡æ–°åˆ†é…
        for service_id in overloaded_services:
            await self._redistribute_load(service_id)
    
    async def _analyze_load_distribution(self) -> Dict[str, float]:
        """åˆ†æè´Ÿè½½åˆ†å¸ƒ"""
        
        all_services = await self.service_registry.get_all_services()
        load_distribution = {}
        
        for service in all_services:
            metrics = self.metrics_collector.get_service_metrics(service.service_id)
            load_distribution[service.service_id] = metrics.get("current_load", 0.0)
        
        return load_distribution
    
    async def _redistribute_load(self, overloaded_service_id: str):
        """é‡æ–°åˆ†é…è´Ÿè½½"""
        
        # 1. æ‰¾åˆ°åŒç±»å‹çš„å…¶ä»–æœåŠ¡
        overloaded_service = await self.service_registry.get_service(
            overloaded_service_id
        )
        
        alternative_services = await self.service_registry.find_services(
            service_type=overloaded_service.service_type,
            exclude_ids=[overloaded_service_id]
        )
        
        # 2. é€‰æ‹©è´Ÿè½½è¾ƒä½çš„æœåŠ¡
        low_load_services = []
        for service in alternative_services:
            metrics = self.metrics_collector.get_service_metrics(service.service_id)
            if metrics.get("current_load", 0.0) < 0.6:  # 60%ä»¥ä¸‹
                low_load_services.append(service)
        
        # 3. æ›´æ–°è·¯ç”±æƒé‡
        if low_load_services:
            await self._update_routing_weights(
                overloaded_service_id,
                low_load_services
            )
    
    def _calculate_resource_requirements(
        self,
        task_definition: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è®¡ç®—èµ„æºéœ€æ±‚"""
        
        service_category = task_definition.get("service_category")
        
        # æ ¹æ®æœåŠ¡ç±»å‹è®¾ç½®é»˜è®¤èµ„æºéœ€æ±‚
        if service_category == "llm":
            return {
                "cpu": 2.0,
                "memory": 4 * 1024 * 1024 * 1024,  # 4GB
                "gpu": 0.5,  # åŠä¸ªGPU
                "network_bandwidth": 100  # Mbps
            }
        elif service_category == "document":
            return {
                "cpu": 4.0,
                "memory": 8 * 1024 * 1024 * 1024,  # 8GB
                "disk_io": 1000,  # IOPS
                "network_bandwidth": 200
            }
        else:
            return {
                "cpu": 1.0,
                "memory": 2 * 1024 * 1024 * 1024,  # 2GB
                "network_bandwidth": 50
            }
```

### 3. æ™ºèƒ½è´Ÿè½½å‡è¡¡å™¨

```python
# src/communication/external/intelligent_load_balancer.py
from typing import Dict, List, Optional, Any
from enum import Enum
import random
import math

class LoadBalancingStrategy(Enum):
    """è´Ÿè½½å‡è¡¡ç­–ç•¥"""
    ROUND_ROBIN = "round_robin"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"
    LEAST_RESPONSE_TIME = "least_response_time"
    COST_OPTIMIZED = "cost_optimized"
    INTELLIGENT = "intelligent"

class IntelligentLoadBalancer:
    """æ™ºèƒ½è´Ÿè½½å‡è¡¡å™¨"""
    
    def __init__(self):
        self.service_counters = {}  # è½®è¯¢è®¡æ•°å™¨
        self.service_weights = {}   # æœåŠ¡æƒé‡
        self.service_metrics = {}   # æœåŠ¡æŒ‡æ ‡
        self.logger = logging.getLogger(__name__)
    
    async def select_service(
        self,
        available_services: List[Dict[str, Any]],
        strategy: str = "intelligent",
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """é€‰æ‹©æœåŠ¡å®ä¾‹"""
        
        if not available_services:
            raise Exception("No available services")
        
        if len(available_services) == 1:
            return available_services[0]
        
        # æ ¹æ®ç­–ç•¥é€‰æ‹©æœåŠ¡
        if strategy == LoadBalancingStrategy.ROUND_ROBIN.value:
            return self._round_robin_select(available_services)
        elif strategy == LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN.value:
            return self._weighted_round_robin_select(available_services)
        elif strategy == LoadBalancingStrategy.LEAST_CONNECTIONS.value:
            return self._least_connections_select(available_services)
        elif strategy == LoadBalancingStrategy.LEAST_RESPONSE_TIME.value:
            return self._least_response_time_select(available_services)
        elif strategy == LoadBalancingStrategy.COST_OPTIMIZED.value:
            return self._cost_optimized_select(available_services)
        elif strategy == LoadBalancingStrategy.INTELLIGENT.value:
            return self._intelligent_select(available_services, context)
        else:
            return self._round_robin_select(available_services)
    
    def _round_robin_select(self, services: List[Dict]) -> Dict:
        """è½®è¯¢é€‰æ‹©"""
        
        service_group = str(hash(tuple(s["service_id"] for s in services)))
        
        if service_group not in self.service_counters:
            self.service_counters[service_group] = 0
        
        selected_index = self.service_counters[service_group] % len(services)
        self.service_counters[service_group] += 1
        
        return services[selected_index]
    
    def _weighted_round_robin_select(self, services: List[Dict]) -> Dict:
        """åŠ æƒè½®è¯¢é€‰æ‹©"""
        
        # è®¡ç®—æƒé‡ï¼ˆåŸºäºæˆåŠŸç‡å’Œå“åº”æ—¶é—´ï¼‰
        weighted_services = []
        for service in services:
            weight = self._calculate_service_weight(service)
            weighted_services.extend([service] * max(1, int(weight * 10)))
        
        return self._round_robin_select(weighted_services)
    
    def _least_connections_select(self, services: List[Dict]) -> Dict:
        """æœ€å°‘è¿æ¥é€‰æ‹©"""
        
        # é€‰æ‹©å½“å‰è´Ÿè½½æœ€ä½çš„æœåŠ¡
        return min(services, key=lambda s: s.get("load", 0.0))
    
    def _least_response_time_select(self, services: List[Dict]) -> Dict:
        """æœ€çŸ­å“åº”æ—¶é—´é€‰æ‹©"""
        
        # é€‰æ‹©å¹³å‡å“åº”æ—¶é—´æœ€çŸ­çš„æœåŠ¡
        return min(services, key=lambda s: s.get("avg_response_time", float('inf')))
    
    def _cost_optimized_select(self, services: List[Dict]) -> Dict:
        """æˆæœ¬ä¼˜åŒ–é€‰æ‹©"""
        
        # åœ¨æ»¡è¶³æ€§èƒ½è¦æ±‚çš„å‰æä¸‹é€‰æ‹©æˆæœ¬æœ€ä½çš„æœåŠ¡
        # è¿‡æ»¤æ‰å“åº”æ—¶é—´è¿‡é•¿æˆ–æˆåŠŸç‡è¿‡ä½çš„æœåŠ¡
        qualified_services = [
            s for s in services
            if s.get("avg_response_time", 0) < 5000  # 5ç§’ä»¥å†…
            and s.get("success_rate", 0) > 0.95      # 95%ä»¥ä¸ŠæˆåŠŸç‡
        ]
        
        if not qualified_services:
            qualified_services = services
        
        # é€‰æ‹©æˆæœ¬æœ€ä½çš„æœåŠ¡
        return min(qualified_services, key=lambda s: s.get("cost_per_request", 0.0))
    
    def _intelligent_select(
        self,
        services: List[Dict],
        context: Optional[Dict] = None
    ) -> Dict:
        """æ™ºèƒ½é€‰æ‹© - ç»¼åˆå¤šä¸ªå› ç´ """
        
        context = context or {}
        
        # è®¡ç®—æ¯ä¸ªæœåŠ¡çš„ç»¼åˆè¯„åˆ†
        scored_services = []
        for service in services:
            score = self._calculate_service_score(service, context)
            scored_services.append((service, score))
        
        # é€‰æ‹©è¯„åˆ†æœ€é«˜çš„æœåŠ¡
        best_service = max(scored_services, key=lambda x: x[1])
        return best_service[0]
    
    def _calculate_service_score(
        self,
        service: Dict[str, Any],
        context: Dict[str, Any]
    ) -> float:
        """è®¡ç®—æœåŠ¡ç»¼åˆè¯„åˆ†"""
        
        # åŸºç¡€æŒ‡æ ‡
        load = service.get("load", 0.0)
        response_time = service.get("avg_response_time", 1000.0)
        success_rate = service.get("success_rate", 1.0)
        cost = service.get("cost_per_request", 0.001)
        
        # å½’ä¸€åŒ–æŒ‡æ ‡ (0-1)
        load_score = max(0, 1 - load)  # è´Ÿè½½è¶Šä½è¶Šå¥½
        response_score = max(0, 1 - min(response_time / 10000, 1))  # å“åº”æ—¶é—´è¶ŠçŸ­è¶Šå¥½
        success_score = success_rate  # æˆåŠŸç‡è¶Šé«˜è¶Šå¥½
        cost_score = max(0, 1 - min(cost / 0.01, 1))  # æˆæœ¬è¶Šä½è¶Šå¥½
        
        # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´æƒé‡
        priority = context.get("priority", 5)
        user_type = context.get("user_type", "standard")
        
        if priority > 7:  # é«˜ä¼˜å…ˆçº§ä»»åŠ¡
            # æ›´é‡è§†å“åº”æ—¶é—´å’ŒæˆåŠŸç‡
            weights = {
                "load": 0.2,
                "response": 0.4,
                "success": 0.3,
                "cost": 0.1
            }
        elif user_type == "premium":  # ä»˜è´¹ç”¨æˆ·
            # å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
            weights = {
                "load": 0.25,
                "response": 0.3,
                "success": 0.3,
                "cost": 0.15
            }
        else:  # æ ‡å‡†ç”¨æˆ·
            # æ›´é‡è§†æˆæœ¬
            weights = {
                "load": 0.2,
                "response": 0.2,
                "success": 0.3,
                "cost": 0.3
            }
        
        # è®¡ç®—åŠ æƒæ€»åˆ†
        total_score = (
            load_score * weights["load"] +
            response_score * weights["response"] +
            success_score * weights["success"] +
            cost_score * weights["cost"]
        )
        
        return total_score
    
    def _calculate_service_weight(self, service: Dict[str, Any]) -> float:
        """è®¡ç®—æœåŠ¡æƒé‡"""
        
        success_rate = service.get("success_rate", 1.0)
        response_time = service.get("avg_response_time", 1000.0)
        load = service.get("load", 0.0)
        
        # æƒé‡è®¡ç®—ï¼šæˆåŠŸç‡é«˜ã€å“åº”æ—¶é—´çŸ­ã€è´Ÿè½½ä½çš„æœåŠ¡æƒé‡é«˜
        weight = success_rate * (1 / max(response_time / 1000, 0.1)) * (1 - load)
        
        return max(0.1, min(weight, 10.0))  # æƒé‡èŒƒå›´ 0.1-10.0
    
    async def update_service_metrics(
        self,
        service_id: str,
        metrics: Dict[str, Any]
    ):
        """æ›´æ–°æœåŠ¡æŒ‡æ ‡"""
        
        self.service_metrics[service_id] = {
            **self.service_metrics.get(service_id, {}),
            **metrics,
            "updated_at": datetime.utcnow().isoformat()
        }
    
    def get_load_balancer_stats(self) -> Dict[str, Any]:
        """è·å–è´Ÿè½½å‡è¡¡å™¨ç»Ÿè®¡ä¿¡æ¯"""
        
        return {
            "total_services": len(self.service_metrics),
            "active_counters": len(self.service_counters),
            "avg_service_load": sum(
                metrics.get("load", 0.0) 
                for metrics in self.service_metrics.values()
            ) / max(len(self.service_metrics), 1),
            "service_metrics": self.service_metrics
        }
```

## ç»Ÿä¸€è°ƒåº¦æµç¨‹

### 1. è¯·æ±‚å¤„ç†æµç¨‹

```mermaid
sequenceDiagram
    participant App as åº”ç”¨å±‚
    participant BIR as BIRè·¯ç”±å™¨
    participant Gateway as æœåŠ¡ç½‘å…³
    participant Coord as ååŒåŸŸ
    participant ExtSvc as å¤–éƒ¨æœåŠ¡

    App->>BIR: å¤–éƒ¨æœåŠ¡è¯·æ±‚
    BIR->>Coord: å‘ç°å¯ç”¨æœåŠ¡
    Coord->>BIR: è¿”å›æœåŠ¡åˆ—è¡¨
    BIR->>BIR: è´Ÿè½½å‡è¡¡é€‰æ‹©
    BIR->>Gateway: è°ƒç”¨å¤–éƒ¨æœåŠ¡
    Gateway->>ExtSvc: HTTP/APIè°ƒç”¨
    ExtSvc-->>Gateway: è¿”å›å“åº”
    Gateway-->>BIR: å¤„ç†åçš„å“åº”
    BIR->>Coord: æ›´æ–°æœåŠ¡æŒ‡æ ‡
    BIR-->>App: è¿”å›æœ€ç»ˆç»“æœ
```

### 2. æœåŠ¡æ³¨å†Œæµç¨‹

```python
# å¤–éƒ¨æœåŠ¡æ³¨å†Œç¤ºä¾‹
async def register_external_services():
    """æ³¨å†Œå¤–éƒ¨æœåŠ¡"""
    
    # ååŒåŸŸæœåŠ¡æ³¨å†Œ
    coordinator = ExternalServiceCoordinator()
    
    # æ³¨å†ŒOpenAIæœåŠ¡
    await coordinator.service_registry.register_service(
        service_name="openai-gpt4",
        service_type="llm",
        endpoint="https://api.openai.com/v1",
        metadata={
            "model": "gpt-4",
            "max_tokens": 4096,
            "cost_per_1k_tokens": 0.03,
            "capabilities": ["text_completion", "chat", "code_generation"]
        }
    )
    
    # æ³¨å†ŒUnstructuredæœåŠ¡
    await coordinator.service_registry.register_service(
        service_name="unstructured-parser",
        service_type="document",
        endpoint="http://unstructured-api:8000",
        metadata={
            "supported_formats": ["pdf", "docx", "xlsx", "pptx"],
            "max_file_size": "50MB",
            "processing_time_avg": "30s"
        }
    )
    
    # é€šä¿¡åŸŸæœåŠ¡ç½‘å…³æ³¨å†Œ
    gateway = ServiceGateway()
    
    # æ³¨å†Œå¯¹åº”çš„é€‚é…å™¨
    await gateway.register_service(
        ServiceConfig(
            service_id="openai-gpt4",
            service_type=ServiceType.LLM_SERVICE,
            base_url="https://api.openai.com/v1",
            api_key=os.getenv("OPENAI_API_KEY")
        ),
        OpenAIAdapter()
    )
```

## é…ç½®ç®¡ç†

### 1. ç»Ÿä¸€é…ç½®æ–‡ä»¶

```yaml
# config/external_services_unified.yaml
external_services:
  coordination:
    # ååŒåŸŸé…ç½®
    service_discovery:
      cache_ttl: 300  # 5åˆ†é’Ÿ
      health_check_interval: 30
      failover_threshold: 3
      
    resource_allocation:
      default_cpu: 2.0
      default_memory: "4Gi"
      max_concurrent_tasks: 100
      
    scheduling_policies:
      llm_services:
        strategy: "cost_optimized"
        max_cost_per_request: 0.05
        min_success_rate: 0.95
        
      document_processing:
        strategy: "least_loaded"
        max_queue_size: 50
        timeout: 300
        
  communication:
    # é€šä¿¡åŸŸé…ç½®
    load_balancing:
      default_strategy: "intelligent"
      health_check_timeout: 5
      circuit_breaker_threshold: 5
      
    caching:
      enabled: true
      ttl:
        llm_responses: 3600      # 1å°æ—¶
        document_parsing: 86400  # 24å°æ—¶
        embeddings: 604800       # 7å¤©
        
    retry_policy:
      max_retries: 3
      backoff_strategy: "exponential"
      base_delay: 1.0
      max_delay: 30.0

  services:
    # LLMæœåŠ¡é…ç½®
    llm_services:
      openai:
        models:
          - name: "gpt-4"
            cost_per_1k_tokens: 0.03
            max_tokens: 4096
            priority: 10
          - name: "gpt-3.5-turbo"
            cost_per_1k_tokens: 0.002
            max_tokens: 4096
            priority: 5
            
      anthropic:
        models:
          - name: "claude-3-sonnet"
            cost_per_1k_tokens: 0.015
            max_tokens: 4096
            priority: 8
            
      local_models:
        - name: "llama2-7b"
          endpoint: "http://local-llm:8080"
          cost_per_1k_tokens: 0.0
          max_tokens: 2048
          priority: 3
          
    # æ–‡æ¡£å¤„ç†æœåŠ¡
    document_services:
      unstructured:
        endpoint: "http://unstructured:8000"
        max_file_size: "50MB"
        supported_formats: ["pdf", "docx", "xlsx", "pptx", "html"]
        timeout: 300
        
    # çŸ¥è¯†å›¾è°±æœåŠ¡
    knowledge_graph:
      graphrag:
        endpoint: "http://graphrag:8001"
        max_documents: 1000
        timeout: 600
        
    # å‘é‡æ•°æ®åº“
    vector_databases:
      chroma:
        endpoint: "http://chroma:8000"
        collections: ["documents", "chunks", "embeddings"]
        
      pinecone:
        api_key: "${PINECONE_API_KEY}"
        environment: "us-west1-gcp"
        index_name: "knowledge-base"
```

## ç›‘æ§å’Œå‘Šè­¦

### 1. å…³é”®æŒ‡æ ‡ç›‘æ§

```python
# å¤–éƒ¨æœåŠ¡ç›‘æ§æŒ‡æ ‡
EXTERNAL_SERVICE_METRICS = {
    "request_count": "å¤–éƒ¨æœåŠ¡è¯·æ±‚æ€»æ•°",
    "success_rate": "æˆåŠŸç‡",
    "avg_response_time": "å¹³å‡å“åº”æ—¶é—´",
    "error_rate": "é”™è¯¯ç‡",
    "cost_per_hour": "æ¯å°æ—¶æˆæœ¬",
    "cache_hit_rate": "ç¼“å­˜å‘½ä¸­ç‡",
    "circuit_breaker_trips": "ç†”æ–­å™¨è§¦å‘æ¬¡æ•°",
    "failover_count": "æ•…éšœè½¬ç§»æ¬¡æ•°",
    "queue_length": "è¯·æ±‚é˜Ÿåˆ—é•¿åº¦",
    "resource_utilization": "èµ„æºåˆ©ç”¨ç‡"
}

# å‘Šè­¦è§„åˆ™
ALERT_RULES = {
    "high_error_rate": {
        "condition": "error_rate > 0.05",  # é”™è¯¯ç‡è¶…è¿‡5%
        "severity": "warning",
        "action": "enable_circuit_breaker"
    },
    "high_response_time": {
        "condition": "avg_response_time > 10000",  # å“åº”æ—¶é—´è¶…è¿‡10ç§’
        "severity": "warning", 
        "action": "switch_to_faster_service"
    },
    "high_cost": {
        "condition": "cost_per_hour > 100",  # æ¯å°æ—¶æˆæœ¬è¶…è¿‡100ç¾å…ƒ
        "severity": "critical",
        "action": "switch_to_cheaper_service"
    },
    "service_unavailable": {
        "condition": "success_rate < 0.9",  # æˆåŠŸç‡ä½äº90%
        "severity": "critical",
        "action": "enable_failover"
    }
}
```

## æ€»ç»“

è¿™ä¸ªç»Ÿä¸€è°ƒåº¦æ–¹æ¡ˆå®ç°äº†ï¼š

### ğŸ¯ **æ ¸å¿ƒä¼˜åŠ¿**

1. **åŒåŸŸåä½œ**ï¼šé€šä¿¡åŸŸè´Ÿè´£è·¯ç”±å’Œè°ƒç”¨ï¼ŒååŒåŸŸè´Ÿè´£è°ƒåº¦å’Œç®¡ç†
2. **æ™ºèƒ½è°ƒåº¦**ï¼šåŸºäºè´Ÿè½½ã€æˆæœ¬ã€å»¶è¿Ÿç­‰å¤šå› ç´ çš„æ™ºèƒ½é€‰æ‹©
3. **é«˜å¯ç”¨æ€§**ï¼šç†”æ–­å™¨ã€æ•…éšœè½¬ç§»ã€é™çº§æœåŠ¡ç­‰å¤šé‡ä¿éšœ
4. **æˆæœ¬ä¼˜åŒ–**ï¼šæ™ºèƒ½æˆæœ¬æ§åˆ¶å’Œèµ„æºä¼˜åŒ–åˆ†é…
5. **ç»Ÿä¸€ç®¡ç†**ï¼šæ‰€æœ‰å¤–éƒ¨æœåŠ¡çš„ç»Ÿä¸€æ³¨å†Œã€ç›‘æ§å’Œæ²»ç†

### ğŸ”§ **æŠ€æœ¯ç‰¹è‰²**

1. **å¢å¼ºBIRè·¯ç”±**ï¼šæ”¯æŒå¤–éƒ¨æœåŠ¡çš„æ™ºèƒ½è·¯ç”±å’Œè´Ÿè½½å‡è¡¡
2. **ååŒåŸŸè°ƒåº¦**ï¼šèµ„æºåˆ†é…ã€ä»»åŠ¡ç¼–æ’ã€ç­–ç•¥ç®¡ç†
3. **å¤šç­–ç•¥è´Ÿè½½å‡è¡¡**ï¼šè½®è¯¢ã€åŠ æƒã€æˆæœ¬ä¼˜åŒ–ã€æ™ºèƒ½é€‰æ‹©
4. **å®Œå–„ç›‘æ§ä½“ç³»**ï¼šå®æ—¶æŒ‡æ ‡ã€å¥åº·æ£€æŸ¥ã€å‘Šè­¦æœºåˆ¶
5. **çµæ´»é…ç½®ç®¡ç†**ï¼šç»Ÿä¸€é…ç½®ã€åŠ¨æ€è°ƒæ•´ã€ç­–ç•¥é©±åŠ¨

è¿™ä¸ªæ–¹æ¡ˆè®©æˆ‘ä»¬çš„ç³»ç»Ÿèƒ½å¤Ÿæ™ºèƒ½åœ°ç®¡ç†å’Œè°ƒåº¦æ‰€æœ‰å¤–éƒ¨æœåŠ¡ï¼Œå®ç°æœ€ä½³çš„æ€§èƒ½ã€æˆæœ¬å’Œå¯ç”¨æ€§å¹³è¡¡ï¼ğŸš€ 