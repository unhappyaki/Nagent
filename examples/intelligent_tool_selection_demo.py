"""
æ™ºèƒ½å·¥å…·é€‰æ‹©æ¼”ç¤º

æ¼”ç¤ºå¦‚ä½•ä»ç®€å•å…³é”®è¯åŒ¹é…å‡çº§åˆ°æ™ºèƒ½å·¥å…·é€‰æ‹©ï¼Œ
æ”¯æŒè¯­ä¹‰ç†è§£ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œå¤šç­–ç•¥èåˆã€‚
"""

import asyncio
import json
import time
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import re


@dataclass
class ToolCandidate:
    """å·¥å…·å€™é€‰è€…"""
    name: str
    description: str
    category: str
    score: float
    match_type: str
    metadata: Dict[str, Any] = None


class MatchType(Enum):
    """åŒ¹é…ç±»å‹"""
    EXACT_KEYWORD = "exact_keyword"
    SEMANTIC_SIMILARITY = "semantic_similarity"
    CATEGORY_MATCH = "category_match"
    CONTEXT_AWARE = "context_aware"
    USAGE_PATTERN = "usage_pattern"


class ToolCategory(Enum):
    """å·¥å…·åˆ†ç±»"""
    DATA_PROCESSING = "æ•°æ®å¤„ç†"
    FILE_OPERATIONS = "æ–‡ä»¶æ“ä½œ"
    NETWORK_COMMUNICATION = "ç½‘ç»œé€šä¿¡"
    SYSTEM_OPERATIONS = "ç³»ç»Ÿæ“ä½œ"
    AI_ML = "AIä¸æœºå™¨å­¦ä¹ "
    DEVELOPMENT = "å¼€å‘å·¥å…·"
    MONITORING = "ç›‘æ§å·¥å…·"


class SimpleToolSelector:
    """ç®€å•å·¥å…·é€‰æ‹©å™¨ - å½“å‰ç³»ç»Ÿçš„å®ç°æ–¹å¼"""
    
    def __init__(self):
        self.tool_mapping = {
            "æœç´¢": "web_search",
            "æŸ¥æ‰¾": "web_search",
            "è®¡ç®—": "calculator",
            "æ—¶é—´": "get_time",
            "å¤©æ°”": "get_weather",
            "æ–‡ä»¶": "file_operations",
            "ç½‘ç»œ": "http_request"
        }
    
    def select_tool(self, intent: str, available_tools: List[Dict[str, Any]]) -> str:
        """ç®€å•çš„å…³é”®è¯åŒ¹é…å·¥å…·é€‰æ‹©"""
        intent_lower = intent.lower()
        
        for keyword, tool_name in self.tool_mapping.items():
            if keyword in intent_lower:
                # æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨
                if any(tool.get("name") == tool_name for tool in available_tools):
                    return tool_name
        
        # è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨å·¥å…·
        return available_tools[0].get("name", "default_tool") if available_tools else "default_tool"


class IntelligentToolSelector:
    """æ™ºèƒ½å·¥å…·é€‰æ‹©å™¨ - æ”¹è¿›ç‰ˆå®ç°"""
    
    def __init__(self):
        self.tool_database = self._init_tool_database()
        self.semantic_patterns = self._init_semantic_patterns()
        self.context_memory = []
        self.usage_stats = {}
        
    def _init_tool_database(self) -> List[Dict[str, Any]]:
        """åˆå§‹åŒ–å·¥å…·æ•°æ®åº“"""
        return [
            {
                "name": "web_search",
                "description": "æ‰§è¡Œç½‘ç»œæœç´¢ï¼ŒæŸ¥æ‰¾äº’è”ç½‘ä¸Šçš„ä¿¡æ¯",
                "category": ToolCategory.DATA_PROCESSING.value,
                "keywords": ["æœç´¢", "æŸ¥æ‰¾", "å¯»æ‰¾", "æ£€ç´¢", "æŸ¥è¯¢", "æ‰¾"],
                "semantic_tags": ["ä¿¡æ¯è·å–", "ç½‘ç»œæŸ¥è¯¢", "å†…å®¹æœç´¢"],
                "usage_count": 150,
                "success_rate": 0.85
            },
            {
                "name": "calculator",
                "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—å’Œè¡¨è¾¾å¼æ±‚å€¼",
                "category": ToolCategory.DATA_PROCESSING.value,
                "keywords": ["è®¡ç®—", "ç®—", "æ•°å­¦", "æ±‚è§£", "è¿ç®—"],
                "semantic_tags": ["æ•°å€¼è®¡ç®—", "æ•°å­¦è¿ç®—", "è¡¨è¾¾å¼æ±‚å€¼"],
                "usage_count": 120,
                "success_rate": 0.95
            },
            {
                "name": "get_time",
                "description": "è·å–å½“å‰æ—¶é—´å’Œæ—¥æœŸä¿¡æ¯",
                "category": ToolCategory.SYSTEM_OPERATIONS.value,
                "keywords": ["æ—¶é—´", "æ—¥æœŸ", "ç°åœ¨", "å½“å‰æ—¶é—´"],
                "semantic_tags": ["æ—¶é—´æŸ¥è¯¢", "æ—¥æœŸè·å–", "æ—¶é—´ä¿¡æ¯"],
                "usage_count": 80,
                "success_rate": 0.98
            },
            {
                "name": "get_weather",
                "description": "è·å–æŒ‡å®šåœ°åŒºçš„å¤©æ°”ä¿¡æ¯",
                "category": ToolCategory.DATA_PROCESSING.value,
                "keywords": ["å¤©æ°”", "æ°”æ¸©", "é™é›¨", "æ™´å¤©", "é˜´å¤©"],
                "semantic_tags": ["å¤©æ°”æŸ¥è¯¢", "æ°”è±¡ä¿¡æ¯", "ç¯å¢ƒæ•°æ®"],
                "usage_count": 90,
                "success_rate": 0.80
            },
            {
                "name": "file_operations",
                "description": "æ‰§è¡Œæ–‡ä»¶è¯»å†™ã€åˆ›å»ºã€åˆ é™¤ç­‰æ“ä½œ",
                "category": ToolCategory.FILE_OPERATIONS.value,
                "keywords": ["æ–‡ä»¶", "è¯»å–", "å†™å…¥", "ä¿å­˜", "åˆ é™¤"],
                "semantic_tags": ["æ–‡ä»¶ç®¡ç†", "æ•°æ®å­˜å‚¨", "æ–‡ä»¶å¤„ç†"],
                "usage_count": 100,
                "success_rate": 0.88
            },
            {
                "name": "http_request",
                "description": "å‘é€HTTPè¯·æ±‚ï¼Œä¸å¤–éƒ¨APIäº¤äº’",
                "category": ToolCategory.NETWORK_COMMUNICATION.value,
                "keywords": ["ç½‘ç»œ", "è¯·æ±‚", "API", "æ¥å£", "è°ƒç”¨"],
                "semantic_tags": ["ç½‘ç»œé€šä¿¡", "APIè°ƒç”¨", "æ•°æ®äº¤æ¢"],
                "usage_count": 70,
                "success_rate": 0.75
            },
            {
                "name": "data_analyzer",
                "description": "åˆ†ææ•°æ®é›†ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š",
                "category": ToolCategory.DATA_PROCESSING.value,
                "keywords": ["åˆ†æ", "ç»Ÿè®¡", "æŠ¥å‘Š", "æ•°æ®", "å›¾è¡¨"],
                "semantic_tags": ["æ•°æ®åˆ†æ", "ç»Ÿè®¡å¤„ç†", "æŠ¥å‘Šç”Ÿæˆ"],
                "usage_count": 60,
                "success_rate": 0.82
            },
            {
                "name": "email_sender",
                "description": "å‘é€ç”µå­é‚®ä»¶é€šçŸ¥",
                "category": ToolCategory.NETWORK_COMMUNICATION.value,
                "keywords": ["é‚®ä»¶", "å‘é€", "é€šçŸ¥", "email"],
                "semantic_tags": ["é‚®ä»¶å‘é€", "æ¶ˆæ¯é€šçŸ¥", "é€šä¿¡å·¥å…·"],
                "usage_count": 45,
                "success_rate": 0.90
            },
            {
                "name": "image_processor",
                "description": "å¤„ç†å’Œç¼–è¾‘å›¾åƒæ–‡ä»¶",
                "category": ToolCategory.AI_ML.value,
                "keywords": ["å›¾åƒ", "å›¾ç‰‡", "å¤„ç†", "ç¼–è¾‘", "ç…§ç‰‡"],
                "semantic_tags": ["å›¾åƒå¤„ç†", "è§†è§‰å¤„ç†", "åª’ä½“ç¼–è¾‘"],
                "usage_count": 35,
                "success_rate": 0.78
            },
            {
                "name": "text_translator",
                "description": "ç¿»è¯‘æ–‡æœ¬å†…å®¹åˆ°ä¸åŒè¯­è¨€",
                "category": ToolCategory.AI_ML.value,
                "keywords": ["ç¿»è¯‘", "è¯­è¨€", "è½¬æ¢", "ä¸­è‹±æ–‡"],
                "semantic_tags": ["è¯­è¨€ç¿»è¯‘", "æ–‡æœ¬è½¬æ¢", "å¤šè¯­è¨€å¤„ç†"],
                "usage_count": 55,
                "success_rate": 0.85
            }
        ]
    
    def _init_semantic_patterns(self) -> Dict[str, List[str]]:
        """åˆå§‹åŒ–è¯­ä¹‰æ¨¡å¼"""
        return {
            "search_intent": [
                r".*?(æœç´¢|æŸ¥æ‰¾|å¯»æ‰¾|æ£€ç´¢|æ‰¾|æŸ¥).*?",
                r".*?(å¸®æˆ‘æ‰¾|å¸®å¿™æ‰¾|èƒ½æ‰¾åˆ°|æ‰¾ä¸€ä¸‹).*?",
                r".*?(æœ‰æ²¡æœ‰|æ˜¯å¦æœ‰|å­˜åœ¨).*?ä¿¡æ¯.*?"
            ],
            "calculation_intent": [
                r".*?(è®¡ç®—|ç®—|æ±‚|è¿ç®—).*?",
                r".*?\d+.*?[+\-*/].*?\d+.*?",
                r".*?(å¤šå°‘|å‡ |æ•°é‡).*?"
            ],
            "time_intent": [
                r".*?(æ—¶é—´|æ—¥æœŸ|ç°åœ¨|å½“å‰).*?",
                r".*?(å‡ ç‚¹|ä»€ä¹ˆæ—¶å€™|ä»Šå¤©).*?"
            ],
            "weather_intent": [
                r".*?(å¤©æ°”|æ°”æ¸©|æ¸©åº¦|ä¸‹é›¨|æ™´å¤©).*?",
                r".*?(ä»Šå¤©.*?å¤©æ°”|æ˜å¤©.*?å¤©æ°”).*?"
            ],
            "file_intent": [
                r".*?(æ–‡ä»¶|ä¿å­˜|è¯»å–|å†™å…¥|åˆ é™¤).*?",
                r".*?(åˆ›å»º.*?æ–‡ä»¶|æ‰“å¼€.*?æ–‡ä»¶).*?"
            ],
            "communication_intent": [
                r".*?(å‘é€|é‚®ä»¶|é€šçŸ¥|æ¶ˆæ¯).*?",
                r".*?(è”ç³»|é€šçŸ¥|å‘Šè¯‰).*?"
            ]
        }
    
    async def select_tool(
        self, 
        intent: str, 
        context: Dict[str, Any] = None
    ) -> Tuple[str, float, Dict[str, Any]]:
        """æ™ºèƒ½å·¥å…·é€‰æ‹©"""
        print(f"\nğŸ” æ™ºèƒ½å·¥å…·é€‰æ‹©å¼€å§‹...")
        print(f"æ„å›¾: {intent}")
        
        # 1. å¤šç­–ç•¥å€™é€‰å·¥å…·å‘ç°
        candidates = await self._discover_candidates(intent, context)
        
        # 2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯„åˆ†
        context_scored_candidates = await self._context_aware_scoring(
            candidates, intent, context
        )
        
        # 3. å¤šç­–ç•¥èåˆé€‰æ‹©
        final_selection = await self._multi_strategy_selection(
            context_scored_candidates, intent, context
        )
        
        # 4. æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
        self._update_usage_stats(final_selection["name"], intent)
        
        print(f"âœ… é€‰æ‹©ç»“æœ: {final_selection['name']} (ç½®ä¿¡åº¦: {final_selection['confidence']:.2f})")
        
        return final_selection["name"], final_selection["confidence"], final_selection["metadata"]
    
    async def _discover_candidates(
        self, 
        intent: str, 
        context: Dict[str, Any] = None
    ) -> List[ToolCandidate]:
        """å‘ç°å€™é€‰å·¥å…·"""
        candidates = []
        
        # 1. å…³é”®è¯åŒ¹é…
        keyword_matches = self._keyword_matching(intent)
        candidates.extend(keyword_matches)
        
        # 2. è¯­ä¹‰æ¨¡å¼åŒ¹é…
        semantic_matches = self._semantic_pattern_matching(intent)
        candidates.extend(semantic_matches)
        
        # 3. åˆ†ç±»åŒ¹é…
        category_matches = self._category_matching(intent)
        candidates.extend(category_matches)
        
        # 4. ä¸Šä¸‹æ–‡åŒ¹é…
        if context:
            context_matches = self._context_matching(intent, context)
            candidates.extend(context_matches)
        
        # å»é‡å¹¶è¿”å›
        unique_candidates = self._deduplicate_candidates(candidates)
        
        print(f"ğŸ“‹ å‘ç° {len(unique_candidates)} ä¸ªå€™é€‰å·¥å…·")
        for candidate in unique_candidates[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"  - {candidate.name}: {candidate.score:.2f} ({candidate.match_type})")
        
        return unique_candidates
    
    def _keyword_matching(self, intent: str) -> List[ToolCandidate]:
        """å…³é”®è¯åŒ¹é…"""
        candidates = []
        intent_lower = intent.lower()
        
        for tool in self.tool_database:
            max_score = 0
            for keyword in tool["keywords"]:
                if keyword in intent_lower:
                    # è®¡ç®—åŒ¹é…åˆ†æ•°
                    score = len(keyword) / len(intent_lower)
                    max_score = max(max_score, score)
            
            if max_score > 0:
                candidates.append(ToolCandidate(
                    name=tool["name"],
                    description=tool["description"],
                    category=tool["category"],
                    score=max_score * 0.8,  # å…³é”®è¯åŒ¹é…åŸºç¡€æƒé‡
                    match_type=MatchType.EXACT_KEYWORD.value,
                    metadata=tool
                ))
        
        return candidates
    
    def _semantic_pattern_matching(self, intent: str) -> List[ToolCandidate]:
        """è¯­ä¹‰æ¨¡å¼åŒ¹é…"""
        candidates = []
        
        # æ„å›¾åˆ†ç±»æ˜ å°„
        intent_tool_mapping = {
            "search_intent": ["web_search", "data_analyzer"],
            "calculation_intent": ["calculator"],
            "time_intent": ["get_time"],
            "weather_intent": ["get_weather"],
            "file_intent": ["file_operations"],
            "communication_intent": ["email_sender", "http_request"]
        }
        
        for intent_type, patterns in self.semantic_patterns.items():
            for pattern in patterns:
                if re.search(pattern, intent, re.IGNORECASE):
                    tool_names = intent_tool_mapping.get(intent_type, [])
                    for tool_name in tool_names:
                        tool_info = next((t for t in self.tool_database if t["name"] == tool_name), None)
                        if tool_info:
                            candidates.append(ToolCandidate(
                                name=tool_info["name"],
                                description=tool_info["description"],
                                category=tool_info["category"],
                                score=0.7,  # è¯­ä¹‰åŒ¹é…åˆ†æ•°
                                match_type=MatchType.SEMANTIC_SIMILARITY.value,
                                metadata=tool_info
                            ))
                    break
        
        return candidates
    
    def _category_matching(self, intent: str) -> List[ToolCandidate]:
        """åˆ†ç±»åŒ¹é…"""
        candidates = []
        
        # åŸºäºæ„å›¾å†…å®¹æ¨æ–­å¯èƒ½çš„å·¥å…·åˆ†ç±»
        category_keywords = {
            ToolCategory.DATA_PROCESSING.value: ["æ•°æ®", "ä¿¡æ¯", "æŸ¥è¯¢", "æœç´¢", "åˆ†æ"],
            ToolCategory.FILE_OPERATIONS.value: ["æ–‡ä»¶", "ä¿å­˜", "è¯»å–", "å†™å…¥"],
            ToolCategory.NETWORK_COMMUNICATION.value: ["ç½‘ç»œ", "å‘é€", "é€šä¿¡", "é‚®ä»¶"],
            ToolCategory.SYSTEM_OPERATIONS.value: ["ç³»ç»Ÿ", "æ—¶é—´", "çŠ¶æ€"],
            ToolCategory.AI_ML.value: ["ç¿»è¯‘", "å›¾åƒ", "è¯†åˆ«", "å¤„ç†"]
        }
        
        intent_lower = intent.lower()
        for category, keywords in category_keywords.items():
            category_score = sum(1 for keyword in keywords if keyword in intent_lower)
            if category_score > 0:
                # æ‰¾åˆ°è¯¥åˆ†ç±»ä¸‹çš„æ‰€æœ‰å·¥å…·
                category_tools = [t for t in self.tool_database if t["category"] == category]
                for tool in category_tools:
                    candidates.append(ToolCandidate(
                        name=tool["name"],
                        description=tool["description"],
                        category=tool["category"],
                        score=min(category_score * 0.2, 0.6),  # åˆ†ç±»åŒ¹é…åˆ†æ•°
                        match_type=MatchType.CATEGORY_MATCH.value,
                        metadata=tool
                    ))
        
        return candidates
    
    def _context_matching(self, intent: str, context: Dict[str, Any]) -> List[ToolCandidate]:
        """ä¸Šä¸‹æ–‡åŒ¹é…"""
        candidates = []
        
        # åˆ†æå¯¹è¯å†å²
        if "conversation_history" in context:
            history = context["conversation_history"]
            if history:
                last_intent = history[-1].get("intent", "")
                # å¦‚æœä¸Šä¸€æ¬¡ä½¿ç”¨äº†æŸä¸ªå·¥å…·ï¼Œå¯èƒ½ä¼šç»§ç»­ä½¿ç”¨ç›¸å…³å·¥å…·
                for tool in self.tool_database:
                    if any(keyword in last_intent.lower() for keyword in tool["keywords"]):
                        candidates.append(ToolCandidate(
                            name=tool["name"],
                            description=tool["description"],
                            category=tool["category"],
                            score=0.4,  # ä¸Šä¸‹æ–‡åŒ¹é…åˆ†æ•°
                            match_type=MatchType.CONTEXT_AWARE.value,
                            metadata=tool
                        ))
        
        return candidates
    
    def _deduplicate_candidates(self, candidates: List[ToolCandidate]) -> List[ToolCandidate]:
        """å»é‡å€™é€‰å·¥å…·ï¼Œä¿ç•™æœ€é«˜åˆ†æ•°"""
        tool_scores = {}
        for candidate in candidates:
            if candidate.name not in tool_scores or candidate.score > tool_scores[candidate.name].score:
                tool_scores[candidate.name] = candidate
        
        return list(tool_scores.values())
    
    async def _context_aware_scoring(
        self, 
        candidates: List[ToolCandidate], 
        intent: str, 
        context: Dict[str, Any] = None
    ) -> List[ToolCandidate]:
        """ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯„åˆ†"""
        for candidate in candidates:
            # åŸºç¡€åˆ†æ•°
            base_score = candidate.score
            
            # ä½¿ç”¨é¢‘ç‡åŠ æƒ
            usage_count = candidate.metadata.get("usage_count", 0)
            usage_bonus = min(usage_count / 200, 0.2)  # æœ€å¤š20%åŠ æˆ
            
            # æˆåŠŸç‡åŠ æƒ
            success_rate = candidate.metadata.get("success_rate", 0.5)
            success_bonus = (success_rate - 0.5) * 0.3  # æˆåŠŸç‡å½±å“
            
            # æ—¶é—´è¡°å‡ï¼ˆæœ€è¿‘ä½¿ç”¨çš„å·¥å…·å¾—åˆ†æ›´é«˜ï¼‰
            time_bonus = 0
            if context and "recent_tools" in context:
                if candidate.name in context["recent_tools"]:
                    time_bonus = 0.1
            
            # ç»¼åˆè¯„åˆ†
            candidate.score = min(base_score + usage_bonus + success_bonus + time_bonus, 1.0)
        
        return sorted(candidates, key=lambda x: x.score, reverse=True)
    
    async def _multi_strategy_selection(
        self, 
        candidates: List[ToolCandidate], 
        intent: str, 
        context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """å¤šç­–ç•¥èåˆé€‰æ‹©"""
        if not candidates:
            return {
                "name": "default_tool",
                "confidence": 0.1,
                "metadata": {"reason": "no_candidates_found"}
            }
        
        # ç­–ç•¥æƒé‡
        strategy_weights = {
            MatchType.EXACT_KEYWORD.value: 0.4,
            MatchType.SEMANTIC_SIMILARITY.value: 0.3,
            MatchType.CATEGORY_MATCH.value: 0.2,
            MatchType.CONTEXT_AWARE.value: 0.1
        }
        
        # è®¡ç®—åŠ æƒåˆ†æ•°
        for candidate in candidates:
            weight = strategy_weights.get(candidate.match_type, 0.1)
            candidate.score *= weight
        
        # é€‰æ‹©æœ€é«˜åˆ†å·¥å…·
        best_candidate = max(candidates, key=lambda x: x.score)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = min(best_candidate.score * 2, 1.0)  # å½’ä¸€åŒ–åˆ°[0,1]
        
        return {
            "name": best_candidate.name,
            "confidence": confidence,
            "metadata": {
                "description": best_candidate.description,
                "category": best_candidate.category,
                "match_type": best_candidate.match_type,
                "candidates_count": len(candidates),
                "selection_reason": f"æœ€ä½³åŒ¹é… ({best_candidate.match_type})"
            }
        }
    
    def _update_usage_stats(self, tool_name: str, intent: str):
        """æ›´æ–°ä½¿ç”¨ç»Ÿè®¡"""
        if tool_name not in self.usage_stats:
            self.usage_stats[tool_name] = {
                "count": 0,
                "intents": [],
                "success_count": 0
            }
        
        self.usage_stats[tool_name]["count"] += 1
        self.usage_stats[tool_name]["intents"].append(intent)
        
        # æ›´æ–°å·¥å…·æ•°æ®åº“ä¸­çš„ä½¿ç”¨è®¡æ•°
        for tool in self.tool_database:
            if tool["name"] == tool_name:
                tool["usage_count"] += 1
                break


class ToolSelectionComparator:
    """å·¥å…·é€‰æ‹©å¯¹æ¯”å™¨"""
    
    def __init__(self):
        self.simple_selector = SimpleToolSelector()
        self.intelligent_selector = IntelligentToolSelector()
        
    async def compare_selections(self, test_cases: List[Dict[str, Any]]):
        """å¯¹æ¯”ä¸¤ç§é€‰æ‹©æ–¹æ³•"""
        print("=" * 60)
        print("ğŸ”¬ å·¥å…·é€‰æ‹©æ–¹æ³•å¯¹æ¯”æµ‹è¯•")
        print("=" * 60)
        
        results = {
            "simple": {"correct": 0, "total": 0, "details": []},
            "intelligent": {"correct": 0, "total": 0, "details": []}
        }
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['intent']}")
            print(f"æœŸæœ›å·¥å…·: {test_case['expected_tool']}")
            
            # ç®€å•é€‰æ‹©å™¨æµ‹è¯•
            simple_result = self.simple_selector.select_tool(
                test_case["intent"], 
                test_case["available_tools"]
            )
            simple_correct = simple_result == test_case["expected_tool"]
            results["simple"]["correct"] += simple_correct
            results["simple"]["total"] += 1
            results["simple"]["details"].append({
                "intent": test_case["intent"],
                "selected": simple_result,
                "expected": test_case["expected_tool"],
                "correct": simple_correct
            })
            
            print(f"  ğŸ”¹ ç®€å•é€‰æ‹©å™¨: {simple_result} {'âœ…' if simple_correct else 'âŒ'}")
            
            # æ™ºèƒ½é€‰æ‹©å™¨æµ‹è¯•
            intelligent_result, confidence, metadata = await self.intelligent_selector.select_tool(
                test_case["intent"],
                test_case.get("context", {})
            )
            intelligent_correct = intelligent_result == test_case["expected_tool"]
            results["intelligent"]["correct"] += intelligent_correct
            results["intelligent"]["total"] += 1
            results["intelligent"]["details"].append({
                "intent": test_case["intent"],
                "selected": intelligent_result,
                "expected": test_case["expected_tool"],
                "correct": intelligent_correct,
                "confidence": confidence,
                "metadata": metadata
            })
            
            print(f"  ğŸ”¹ æ™ºèƒ½é€‰æ‹©å™¨: {intelligent_result} (ç½®ä¿¡åº¦: {confidence:.2f}) {'âœ…' if intelligent_correct else 'âŒ'}")
            if metadata:
                print(f"    ç†ç”±: {metadata.get('selection_reason', 'N/A')}")
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 60)
        
        simple_accuracy = results["simple"]["correct"] / results["simple"]["total"]
        intelligent_accuracy = results["intelligent"]["correct"] / results["intelligent"]["total"]
        
        print(f"ç®€å•é€‰æ‹©å™¨å‡†ç¡®ç‡: {simple_accuracy:.2%} ({results['simple']['correct']}/{results['simple']['total']})")
        print(f"æ™ºèƒ½é€‰æ‹©å™¨å‡†ç¡®ç‡: {intelligent_accuracy:.2%} ({results['intelligent']['correct']}/{results['intelligent']['total']})")
        print(f"å‡†ç¡®ç‡æå‡: {intelligent_accuracy - simple_accuracy:.2%}")
        
        return results


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½å·¥å…·é€‰æ‹©æ¼”ç¤ºå¼€å§‹")
    
    # å‡†å¤‡æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "intent": "å¸®æˆ‘æœç´¢ä¸€ä¸‹Pythonæ•™ç¨‹",
            "expected_tool": "web_search",
            "available_tools": [
                {"name": "web_search"}, {"name": "calculator"}, 
                {"name": "get_time"}, {"name": "file_operations"}
            ],
            "context": {"user_id": "user1", "conversation_history": []}
        },
        {
            "intent": "æˆ‘æƒ³çŸ¥é“ç°åœ¨å‡ ç‚¹äº†",
            "expected_tool": "get_time",
            "available_tools": [
                {"name": "web_search"}, {"name": "calculator"}, 
                {"name": "get_time"}, {"name": "get_weather"}
            ],
            "context": {"user_id": "user1"}
        },
        {
            "intent": "å¸®æˆ‘ç®—ä¸€ä¸‹ 123 + 456 ç­‰äºå¤šå°‘",
            "expected_tool": "calculator",
            "available_tools": [
                {"name": "web_search"}, {"name": "calculator"}, 
                {"name": "get_time"}, {"name": "file_operations"}
            ]
        },
        {
            "intent": "æŸ¥çœ‹ä»Šå¤©çš„å¤©æ°”æƒ…å†µ",
            "expected_tool": "get_weather",
            "available_tools": [
                {"name": "web_search"}, {"name": "get_weather"}, 
                {"name": "get_time"}, {"name": "file_operations"}
            ]
        },
        {
            "intent": "èƒ½å¸®æˆ‘æ‰¾åˆ°ç›¸å…³çš„èµ„æ–™å—",
            "expected_tool": "web_search",
            "available_tools": [
                {"name": "web_search"}, {"name": "data_analyzer"}, 
                {"name": "file_operations"}, {"name": "calculator"}
            ]
        },
        {
            "intent": "æˆ‘éœ€è¦ä¿å­˜è¿™ä¸ªæ–‡æ¡£",
            "expected_tool": "file_operations",
            "available_tools": [
                {"name": "web_search"}, {"name": "file_operations"}, 
                {"name": "email_sender"}, {"name": "calculator"}
            ]
        },
        {
            "intent": "è¯·ç¿»è¯‘è¿™æ®µè‹±æ–‡",
            "expected_tool": "text_translator",
            "available_tools": [
                {"name": "text_translator"}, {"name": "web_search"}, 
                {"name": "file_operations"}, {"name": "image_processor"}
            ]
        },
        {
            "intent": "å‘é€é‚®ä»¶é€šçŸ¥ç»™å›¢é˜Ÿ",
            "expected_tool": "email_sender",
            "available_tools": [
                {"name": "email_sender"}, {"name": "http_request"}, 
                {"name": "file_operations"}, {"name": "web_search"}
            ]
        },
        {
            "intent": "å¤„ç†è¿™å¼ å›¾ç‰‡",
            "expected_tool": "image_processor",
            "available_tools": [
                {"name": "image_processor"}, {"name": "file_operations"}, 
                {"name": "data_analyzer"}, {"name": "web_search"}
            ]
        },
        {
            "intent": "åˆ†æè¿™äº›æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š",
            "expected_tool": "data_analyzer",
            "available_tools": [
                {"name": "data_analyzer"}, {"name": "web_search"}, 
                {"name": "file_operations"}, {"name": "calculator"}
            ]
        }
    ]
    
    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    comparator = ToolSelectionComparator()
    results = await comparator.compare_selections(test_cases)
    
    # å±•ç¤ºæ™ºèƒ½é€‰æ‹©å™¨çš„é¢å¤–èƒ½åŠ›
    print("\n" + "=" * 60)
    print("ğŸ¯ æ™ºèƒ½é€‰æ‹©å™¨ç‰¹æ®Šèƒ½åŠ›æ¼”ç¤º")
    print("=" * 60)
    
    intelligent_selector = IntelligentToolSelector()
    
    # 1. è¯­ä¹‰ç†è§£èƒ½åŠ›
    print("\n1ï¸âƒ£ è¯­ä¹‰ç†è§£èƒ½åŠ›æµ‹è¯•:")
    semantic_tests = [
        "èƒ½ä¸èƒ½å¸®æˆ‘æ‰¾ä¸€ä¸‹ç›¸å…³ä¿¡æ¯",  # åº”è¯¥é€‰æ‹©web_search
        "éº»çƒ¦ç®—ä¸€ä¸‹è¿™ä¸ªè¡¨è¾¾å¼",        # åº”è¯¥é€‰æ‹©calculator
        "ç°åœ¨æ˜¯ä»€ä¹ˆæ—¶é—´",            # åº”è¯¥é€‰æ‹©get_time
    ]
    
    for test_intent in semantic_tests:
        result, confidence, metadata = await intelligent_selector.select_tool(test_intent)
        print(f"  '{test_intent}' -> {result} (ç½®ä¿¡åº¦: {confidence:.2f})")
    
    # 2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›
    print("\n2ï¸âƒ£ ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›æµ‹è¯•:")
    context_with_history = {
        "conversation_history": [
            {"intent": "æœç´¢Pythonæ•™ç¨‹", "selected_tool": "web_search"},
            {"intent": "æŸ¥çœ‹æœç´¢ç»“æœ", "selected_tool": "web_search"}
        ],
        "recent_tools": ["web_search"],
        "user_id": "user1"
    }
    
    result, confidence, metadata = await intelligent_selector.select_tool(
        "ç»§ç»­æŸ¥æ‰¾ç›¸å…³èµ„æ–™", context_with_history
    )
    print(f"  ä¸Šä¸‹æ–‡æ„ŸçŸ¥é€‰æ‹©: {result} (ç½®ä¿¡åº¦: {confidence:.2f})")
    print(f"  é€‰æ‹©ç†ç”±: {metadata.get('selection_reason', 'N/A')}")
    
    # 3. ä½¿ç”¨ç»Ÿè®¡å±•ç¤º
    print("\n3ï¸âƒ£ å·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
    usage_stats = intelligent_selector.usage_stats
    if usage_stats:
        for tool_name, stats in usage_stats.items():
            print(f"  {tool_name}: ä½¿ç”¨ {stats['count']} æ¬¡")
    else:
        print("  æš‚æ— ä½¿ç”¨ç»Ÿè®¡æ•°æ®")
    
    print("\nâœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ æ™ºèƒ½å·¥å…·é€‰æ‹©çš„ä¼˜åŠ¿:")
    print("  1. è¯­ä¹‰ç†è§£ï¼šèƒ½ç†è§£åŒä¹‰è¯å’Œç›¸ä¼¼è¡¨è¾¾")
    print("  2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼šè€ƒè™‘å¯¹è¯å†å²å’Œç”¨æˆ·åå¥½")
    print("  3. å¤šç­–ç•¥èåˆï¼šç»“åˆå…³é”®è¯ã€è¯­ä¹‰ã€åˆ†ç±»ç­‰å¤šç§åŒ¹é…æ–¹å¼")
    print("  4. è‡ªé€‚åº”å­¦ä¹ ï¼šæ ¹æ®ä½¿ç”¨æƒ…å†µæŒç»­ä¼˜åŒ–é€‰æ‹©ç­–ç•¥")
    print("  5. ç½®ä¿¡åº¦è¯„ä¼°ï¼šæä¾›é€‰æ‹©ç»“æœçš„å¯ä¿¡åº¦è¯„åˆ†")


if __name__ == "__main__":
    asyncio.run(main()) 